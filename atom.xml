<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>花不醉的小花园</title>
  
  <subtitle>携一生所爱，看遍世间美好</subtitle>
  <link href="/MyBlog/atom.xml" rel="self"/>
  
  <link href="https://winyter.github.io/MyBlog/"/>
  <updated>2020-07-25T10:57:03.563Z</updated>
  <id>https://winyter.github.io/MyBlog/</id>
  
  <author>
    <name>winyter</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CentOS 7 修改网卡配置</title>
    <link href="https://winyter.github.io/MyBlog/2020/07/22/CentOS7x-Network-Config/"/>
    <id>https://winyter.github.io/MyBlog/2020/07/22/CentOS7x-Network-Config/</id>
    <published>2020-07-22T14:30:33.000Z</published>
    <updated>2020-07-25T10:57:03.563Z</updated>
    
    <content type="html"><![CDATA[<hr><blockquote><p>本文档仅提供傻瓜式的配置模板，没有对网卡配置项进行详细的解读</p></blockquote><a id="more"></a><p>配置模板</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TYPE&#x3D;Ethernet</span><br><span class="line">PROXY_METHOD&#x3D;none</span><br><span class="line">BROWSER_ONLY&#x3D;no</span><br><span class="line">BOOTPROTO&#x3D;static</span><br><span class="line">DEFROUTE&#x3D;yes</span><br><span class="line">IPV4_FAILURE_FATAL&#x3D;no</span><br><span class="line">IPV6INIT&#x3D;yes</span><br><span class="line">IPV6_AUTOCONF&#x3D;yes</span><br><span class="line">IPV6_DEFROUTE&#x3D;yes</span><br><span class="line">IPV6_FAILURE_FATAL&#x3D;no</span><br><span class="line">IPV6_ADDR_GEN_MODE&#x3D;stable-privacy</span><br><span class="line">NAME&#x3D;eno3</span><br><span class="line">UUID&#x3D;c5a9ccc6-a5a1-44e2-bf62-f7af9b472d6b</span><br><span class="line">DEVICE&#x3D;eno3</span><br><span class="line">ONBOOT&#x3D;yes</span><br><span class="line">IPADDR&#x3D;162.168.1.100</span><br><span class="line">PREFIX&#x3D;24</span><br><span class="line">GATEWAY&#x3D;162.168.1.254</span><br></pre></td></tr></table></figure><p>关闭界面网络管理服务</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node1]# systemctl stop NetworkManager.service</span><br><span class="line">[root@node1]# systemctl disable NetworkManager.service</span><br><span class="line">[root@node1]# systemctl stauts NetworkManager.service</span><br></pre></td></tr></table></figure><p>重启网卡服务</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node1]# systemctl restart network</span><br><span class="line">[root@node1]# systemctl status network</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;本文档仅提供傻瓜式的配置模板，没有对网卡配置项进行详细的解读&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="CS Soft" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/"/>
    
      <category term="OS" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/OS/"/>
    
      <category term="Unix" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/OS/Unix/"/>
    
      <category term="Linux" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/OS/Unix/Linux/"/>
    
    
      <category term="OS" scheme="https://winyter.github.io/MyBlog/tags/OS/"/>
    
      <category term="Linux" scheme="https://winyter.github.io/MyBlog/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Ambari 安装 Hive 失败，报 “Table ‘hive.dbs’ doesn’t exist”</title>
    <link href="https://winyter.github.io/MyBlog/2020/07/22/ERROR-ambari-install-hive-table-doesnt-exist/"/>
    <id>https://winyter.github.io/MyBlog/2020/07/22/ERROR-ambari-install-hive-table-doesnt-exist/</id>
    <published>2020-07-22T14:28:05.000Z</published>
    <updated>2020-07-25T10:59:55.159Z</updated>
    
    <content type="html"><![CDATA[<hr><p>参考来源：<a href="https://blog.csdn.net/zheng911209/article/details/78718303" target="_blank" rel="noopener">https://blog.csdn.net/zheng911209/article/details/78718303</a></p><hr><p><strong>问题现象</strong>：<br>使用 Ambari 安装 Hive，在启动 Hive 的时候，无法启动 HiveServer2，且 Ambari有报错：“ZooKeeper node /hiveserver2 is not ready yet”</p><a id="more"></a><p><strong>问题定位</strong>：<br>在查看 HiveServer2 的日志时，可以看到：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2017-12-05T11:52:50,446 WARN [ecd471e5-d4b9-40b4-bc9a-644fc411f415 main] metastore.MetaStoreDirectSql: Self-test query [select “DB_ID” from “DBS”] failed; direct SQL is disabled</span><br><span class="line">javax.jdo.JDODataStoreException: Error executing SQL query “select “DB_ID” from “DBS”“.</span><br><span class="line">at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:543) ~[datanucleus-api-jdo-4.2.4.jar:?]</span><br><span class="line">……</span><br><span class="line">Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Table ‘hive.dbs’ doesn’t exist</span><br><span class="line">……</span><br><span class="line">2017-12-05T11:52:50,457 ERROR [ecd471e5-d4b9-40b4-bc9a-644fc411f415 main] metastore.RetryingHMSHandler: MetaException(message:Version information not found in metastore. )</span><br></pre></td></tr></table></figure><p><strong>问题原因</strong>：<br>没生成源数据表</p><p><strong>解决问题</strong>：<br>1、打开 <code>hive-site.xml</code>，设置如下为 <code>true</code>：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;datanucleus.schema.autoCreateAll&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure><p>2、再执行命令：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">schematool -dbType mysql -initSchema</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;参考来源：&lt;a href=&quot;https://blog.csdn.net/zheng911209/article/details/78718303&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://blog.csdn.net/zheng911209/article/details/78718303&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;问题现象&lt;/strong&gt;：&lt;br&gt;使用 Ambari 安装 Hive，在启动 Hive 的时候，无法启动 HiveServer2，且 Ambari有报错：“ZooKeeper node /hiveserver2 is not ready yet”&lt;/p&gt;
    
    </summary>
    
    
      <category term="CS Concept" scheme="https://winyter.github.io/MyBlog/categories/CS-Concept/"/>
    
      <category term="Big Data" scheme="https://winyter.github.io/MyBlog/categories/CS-Concept/Big-Data/"/>
    
    
      <category term="ERROR" scheme="https://winyter.github.io/MyBlog/tags/ERROR/"/>
    
      <category term="Hive" scheme="https://winyter.github.io/MyBlog/tags/Hive/"/>
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/tags/Ambari/"/>
    
  </entry>
  
  <entry>
    <title>解决 Hive 重启时，Metastore 报：MetaException(message:Hive Schema version 2.3.0 does not match metastore&#39;s schema version 1.2.0</title>
    <link href="https://winyter.github.io/MyBlog/2020/07/22/ERROR-Hive-restart-schema-version-unmatched/"/>
    <id>https://winyter.github.io/MyBlog/2020/07/22/ERROR-Hive-restart-schema-version-unmatched/</id>
    <published>2020-07-22T14:23:25.000Z</published>
    <updated>2020-07-25T10:59:32.479Z</updated>
    
    <content type="html"><![CDATA[<hr><p>参考来源：<a href="https://blog.csdn.net/struggling_rong/article/details/82598277" target="_blank" rel="noopener">https://blog.csdn.net/struggling_rong/article/details/82598277</a></p><hr><p><strong>问题现象</strong>：<br>使用 Ambari 重启 Hive 时，遇到在启动 HiveServer2 失败，报错为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">resource_management.core.exceptions.Fail: ZooKeeper node &#x2F;hiveserver2 is not ready yet</span><br></pre></td></tr></table></figure><a id="more"></a><p><strong>问题定位</strong>：<br>在查看 HiveServer2 的日志时，可以看到：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-07-21T17:55:41,864 INFO  [main]: sqlstd.SQLStdHiveAccessController (SQLStdHiveAccessController.java:&lt;init&gt;(95)) - Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString&#x3D;53ee998b-175a-4bc8-985c-a27bfc138166, clientType&#x3D;HIVESERVER2]</span><br><span class="line">2020-07-21T17:55:41,869 WARN  [main]: session.SessionState (SessionState.java:setAuthorizerV2Config(903)) - METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.</span><br><span class="line">2020-07-21T17:55:42,352 INFO  [main]: hive.metastore (HiveMetaStoreClient.java:open(407)) - Trying to connect to metastore with URI thrift:&#x2F;&#x2F;zz-hadoop2:9083</span><br><span class="line">2020-07-21T17:55:42,381 WARN  [main]: hive.metastore (HiveMetaStoreClient.java:open(490)) - Failed to connect to the MetaStore Server...</span><br><span class="line">2020-07-21T17:55:42,381 INFO  [main]: hive.metastore (HiveMetaStoreClient.java:open(521)) - Waiting 5 seconds before next connection attempt.</span><br><span class="line">......</span><br><span class="line">......</span><br><span class="line">......</span><br><span class="line">2020-07-21T17:57:37,424 INFO  [main]: hive.metastore (HiveMetaStoreClient.java:open(407)) - Trying to connect to metastore with URI thrift:&#x2F;&#x2F;zz-hadoop2:9083</span><br><span class="line">2020-07-21T17:57:37,425 WARN  [main]: hive.metastore (HiveMetaStoreClient.java:open(490)) - Failed to connect to the MetaStore Server...</span><br><span class="line">2020-07-21T17:57:37,425 INFO  [main]: hive.metastore (HiveMetaStoreClient.java:open(521)) - Waiting 5 seconds before next connection attempt.</span><br><span class="line">2020-07-21T17:57:42,434 WARN  [main]: metadata.Hive (Hive.java:registerAllFunctionsOnce(234)) - Failed to register all functions.</span><br><span class="line">java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</span><br><span class="line">        at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1701) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:83) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.&lt;init&gt;(Hive.java:388) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.session.SessionState.setAuthorizerV2Config(SessionState.java:913) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:877) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.session.SessionState.applyAuthorizationPolicy(SessionState.java:1683) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hive.service.cli.CLIService.applyAuthorizationConfigPolicy(CLIService.java:130) ~[hive-service-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hive.service.cli.CLIService.init(CLIService.java:114) ~[hive-service-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hive.service.CompositeService.init(CompositeService.java:59) ~[hive-service-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hive.service.server.HiveServer2.init(HiveServer2.java:142) ~[hive-service-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hive.service.server.HiveServer2.startHiveServer2(HiveServer2.java:607) ~[hive-service-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hive.service.server.HiveServer2.access$700(HiveServer2.java:100) ~[hive-service-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hive.service.server.HiveServer2$StartOptionExecutor.execute(HiveServer2.java:855) ~[hive-service-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hive.service.server.HiveServer2.main(HiveServer2.java:724) ~[hive-service-2.3.3.jar:2.3.3]</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_181]</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_181]</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_181]</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_181]</span><br><span class="line">        at org.apache.hadoop.util.RunJar.run(RunJar.java:233) ~[hadoop-common-2.7.3.2.6.3.0-235.jar:?]</span><br><span class="line">        at org.apache.hadoop.util.RunJar.main(RunJar.java:148) ~[hadoop-common-2.7.3.2.6.3.0-235.jar:?]</span><br><span class="line">Caused by: java.lang.reflect.InvocationTargetException</span><br><span class="line">        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_181]</span><br><span class="line">        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_181]</span><br><span class="line">        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_181]</span><br><span class="line">        at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_181]</span><br><span class="line">        at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1699) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        ... 30 more</span><br><span class="line">Caused by: org.apache.hadoop.hive.metastore.api.MetaException: Could not connect to meta store using any of the URIs provided. Most recent failure: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused (Connection refused)</span><br><span class="line">        at org.apache.thrift.transport.TSocket.open(TSocket.java:226)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:480)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:247)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:70)</span><br><span class="line">        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)</span><br><span class="line">        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)</span><br><span class="line">        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1699)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:83)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.&lt;init&gt;(Hive.java:388)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)</span><br><span class="line">        at org.apache.hadoop.hive.ql.session.SessionState.setAuthorizerV2Config(SessionState.java:913)</span><br><span class="line">        at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:877)</span><br><span class="line">        at org.apache.hadoop.hive.ql.session.SessionState.applyAuthorizationPolicy(SessionState.java:1683)</span><br><span class="line">        at org.apache.hive.service.cli.CLIService.applyAuthorizationConfigPolicy(CLIService.java:130)</span><br><span class="line">        at org.apache.hive.service.cli.CLIService.init(CLIService.java:114)</span><br><span class="line">        at org.apache.hive.service.CompositeService.init(CompositeService.java:59)</span><br><span class="line">        at org.apache.hive.service.server.HiveServer2.init(HiveServer2.java:142)</span><br><span class="line">        at org.apache.hive.service.server.HiveServer2.startHiveServer2(HiveServer2.java:607)</span><br><span class="line">        at org.apache.hive.service.server.HiveServer2.access$700(HiveServer2.java:100)</span><br><span class="line">        at org.apache.hive.service.server.HiveServer2$StartOptionExecutor.execute(HiveServer2.java:855)</span><br><span class="line">        at org.apache.hive.service.server.HiveServer2.main(HiveServer2.java:724)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">        at org.apache.hadoop.util.RunJar.run(RunJar.java:233)</span><br><span class="line">        at org.apache.hadoop.util.RunJar.main(RunJar.java:148)</span><br><span class="line">Caused by: java.net.ConnectException: Connection refused (Connection refused)</span><br><span class="line">        at java.net.PlainSocketImpl.socketConnect(Native Method)</span><br><span class="line">        at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)</span><br><span class="line">        at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)</span><br><span class="line">        at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)</span><br><span class="line">        at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)</span><br><span class="line">        at java.net.Socket.connect(Socket.java:589)</span><br><span class="line">        at org.apache.thrift.transport.TSocket.open(TSocket.java:221)</span><br><span class="line">        ... 38 more</span><br><span class="line"></span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:529) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:247) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:70) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_181]</span><br><span class="line">        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_181]</span><br><span class="line">        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_181]</span><br><span class="line">        at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_181]</span><br><span class="line">        at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1699) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        ... 30 more</span><br><span class="line">2020-07-21T17:57:42,461 INFO  [main]: server.HiveServer2 (HiveServer2.java:stop(518)) - Shutting down HiveServer2</span><br><span class="line">2020-07-21T17:57:42,460 ERROR [main]: session.SessionState (SessionState.java:setupAuth(884)) - Error setting up authorization: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</span><br><span class="line">org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</span><br><span class="line">        at org.apache.hadoop.hive.ql.session.SessionState.setAuthorizerV2Config(SessionState.java:917) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:877) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.session.SessionState.applyAuthorizationPolicy(SessionState.java:1683) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hive.service.cli.CLIService.applyAuthorizationConfigPolicy(CLIService.java:130) ~[hive-service-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hive.service.cli.CLIService.init(CLIService.java:114) ~[hive-service-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hive.service.CompositeService.init(CompositeService.java:59) ~[hive-service-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hive.service.server.HiveServer2.init(HiveServer2.java:142) ~[hive-service-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hive.service.server.HiveServer2.startHiveServer2(HiveServer2.java:607) ~[hive-service-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hive.service.server.HiveServer2.access$700(HiveServer2.java:100) ~[hive-service-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hive.service.server.HiveServer2$StartOptionExecutor.execute(HiveServer2.java:855) ~[hive-service-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hive.service.server.HiveServer2.main(HiveServer2.java:724) ~[hive-service-2.3.3.jar:2.3.3]</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_181]</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_181]</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_181]</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_181]</span><br><span class="line">        at org.apache.hadoop.util.RunJar.run(RunJar.java:233) ~[hadoop-common-2.7.3.2.6.3.0-235.jar:?]</span><br><span class="line">        at org.apache.hadoop.util.RunJar.main(RunJar.java:148) ~[hadoop-common-2.7.3.2.6.3.0-235.jar:?]</span><br><span class="line">Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:236) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.&lt;init&gt;(Hive.java:388) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        at org.apache.hadoop.hive.ql.session.SessionState.setAuthorizerV2Config(SessionState.java:913) ~[hive-exec-2.3.3.jar:2.3.3]</span><br><span class="line">        ... 16 more</span><br><span class="line">......</span><br><span class="line">......</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>可以看到是因为 Hive 的 Metastore 无法访问导致 HiveServer2 启动失败，于是，再去看 Metastore 的日志：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2020-07-21T17:55:41,118 ERROR [main]: metastore.RetryingHMSHandler (RetryingHMSHandler.java:invokeInternal(204)) - MetaException(message:Hive Schema version 2.3.0 does not match metastore&#39;s schema version 1.2.0 Metastore is not upgraded or corrupt)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:7579)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:7542)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:101)</span><br><span class="line">        at com.sun.proxy.$Proxy24.verifySchema(Unknown Source)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:591)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:584)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:651)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:427)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:79)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6887)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6882)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore.startMetaStore(HiveMetaStore.java:7140)</span><br><span class="line">        at org.apache.hadoop.hive.metastore.HiveMetaStore.main(HiveMetaStore.java:7067)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">        at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">        at org.apache.hadoop.util.RunJar.run(RunJar.java:233)</span><br><span class="line">        at org.apache.hadoop.util.RunJar.main(RunJar.java:148)</span><br></pre></td></tr></table></figure><p><strong>问题原因</strong>：<br><code>Hive Schema version 2.3.0 does not match metastore&#39;s schema version 1.2.0 Metastore is not upgraded or corrupt</code>问题的核心就在这一句报错，即 Hive 的 Schema 版本不兼容</p><p><strong>解决问题</strong>：</p><ul><li><p>临时解决：<br>在 mysql（假定 metastore 的数据库为 mysql）中，切换到 hive 库，执行如下命令</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">UPDATE VERSION SET SCHEMA_VERSION&#x3D;&#39;2.3.0&#39;, VERSION_COMMENT&#x3D;&#39;fix conflict&#39; where VER_ID&#x3D;1;</span><br></pre></td></tr></table></figure><p>这样解决后，当通过 spark 应用再创建新表时仍会报错。</p></li><li><p>更好的解决：</p></li></ul><ol><li>metastore 模式使用remote方式</li><li>通过cdh来解决版本问题</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;参考来源：&lt;a href=&quot;https://blog.csdn.net/struggling_rong/article/details/82598277&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://blog.csdn.net/struggling_rong/article/details/82598277&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;问题现象&lt;/strong&gt;：&lt;br&gt;使用 Ambari 重启 Hive 时，遇到在启动 HiveServer2 失败，报错为：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;resource_management.core.exceptions.Fail: ZooKeeper node &amp;#x2F;hiveserver2 is not ready yet&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="CS Concept" scheme="https://winyter.github.io/MyBlog/categories/CS-Concept/"/>
    
      <category term="Big Data" scheme="https://winyter.github.io/MyBlog/categories/CS-Concept/Big-Data/"/>
    
    
      <category term="ERROR" scheme="https://winyter.github.io/MyBlog/tags/ERROR/"/>
    
      <category term="Hive" scheme="https://winyter.github.io/MyBlog/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>《数学之美》笔记系列——第二章</title>
    <link href="https://winyter.github.io/MyBlog/2020/07/22/beauty-of-mathematics-notes-chapter2/"/>
    <id>https://winyter.github.io/MyBlog/2020/07/22/beauty-of-mathematics-notes-chapter2/</id>
    <published>2020-07-22T14:18:08.000Z</published>
    <updated>2020-07-25T11:01:02.698Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="第二章-自然语言处理——从规则到统计"><a href="#第二章-自然语言处理——从规则到统计" class="headerlink" title="第二章 自然语言处理——从规则到统计"></a>第二章 自然语言处理——从规则到统计</h2><a id="more"></a><hr><h3 id="1、机器智能"><a href="#1、机器智能" class="headerlink" title="1、机器智能"></a>1、机器智能</h3><hr><p>图灵测试（Turing Test）：让人和机器进行交流，如果人无法判断自己交流的对象是人还是机器，那么就说明这个机器有智能。</p><p>1956 年，“达特茅斯夏季人工智能研究会议”</p><p>20 世纪 60 年代，分析语句和获取语义。句法分析树（Syntactic Parse Tree）、重写规则（Rewrite Rules）。这个方法的问题：文法规则全靠人工，而真实语句太多，人工无法完成，且会出现矛盾；即使能够写出涵盖所有自然语言现象的语法规则集合，也很难用计算机来解析，因为自然语言是上下文有关文法（Context Dependent Grammar），不是计算机高级语言的上下文无关文法（Context Independent Grammar），而上下文有关算法的计算复杂度（Computational Complexity）极大。</p><h3 id="2、从规则到统计"><a href="#2、从规则到统计" class="headerlink" title="2、从规则到统计"></a>2、从规则到统计</h3><hr><p>上世纪 70 年代，基于规则的句法分析很快就走到了尽头，而对于语义的处理遇到了更大的麻烦。首先，自然语言中词的多义性很难用规则来描述，而是严重依赖于上下文，甚至是“世界的知识”（World Knowledge）或者常识。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><hr><p>基于统计的自然语言处理方法，在数学模型上和通信是想通的，甚至就是相同的。因此，数学意义上的自然语言处理又和语言的初衷——通信联系在一起了。但是，科学家用了几十年才认识到这种联系。</p>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h2 id=&quot;第二章-自然语言处理——从规则到统计&quot;&gt;&lt;a href=&quot;#第二章-自然语言处理——从规则到统计&quot; class=&quot;headerlink&quot; title=&quot;第二章 自然语言处理——从规则到统计&quot;&gt;&lt;/a&gt;第二章 自然语言处理——从规则到统计&lt;/h2&gt;
    
    </summary>
    
    
      <category term="CS Concept" scheme="https://winyter.github.io/MyBlog/categories/CS-Concept/"/>
    
      <category term="Reading Notes" scheme="https://winyter.github.io/MyBlog/categories/CS-Concept/Reading-Notes/"/>
    
    
      <category term="CS Concept" scheme="https://winyter.github.io/MyBlog/tags/CS-Concept/"/>
    
      <category term="Math" scheme="https://winyter.github.io/MyBlog/tags/Math/"/>
    
      <category term="Reading" scheme="https://winyter.github.io/MyBlog/tags/Reading/"/>
    
      <category term="Notes" scheme="https://winyter.github.io/MyBlog/tags/Notes/"/>
    
  </entry>
  
  <entry>
    <title>《数学之美》笔记系列——第一章</title>
    <link href="https://winyter.github.io/MyBlog/2020/07/12/beauty-of-mathematics-notes-chapter1/"/>
    <id>https://winyter.github.io/MyBlog/2020/07/12/beauty-of-mathematics-notes-chapter1/</id>
    <published>2020-07-12T14:37:05.000Z</published>
    <updated>2020-07-25T11:00:46.911Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="第一章-文字和语言-vs-数字和信息"><a href="#第一章-文字和语言-vs-数字和信息" class="headerlink" title="第一章 文字和语言 vs 数字和信息"></a>第一章 文字和语言 vs 数字和信息</h2><hr><p>数字、文字、语言都是信息的载体，他们诞生的目的，是为了让信息更好的传播</p><a id="more"></a><h3 id="1、信息"><a href="#1、信息" class="headerlink" title="1、信息"></a>1、信息</h3><hr><p>早期人类利用声音进行通信，和现在最先进的通信，在原理上没有任何差别</p><p>信息[信息源]  &gt;&gt;(怪叫声  编码)&gt;&gt;  信息[信道]  &gt;&gt;(听到的声音  解码)&gt;&gt;  信息[接受者]</p><h3 id="2、文字和数字"><a href="#2、文字和数字" class="headerlink" title="2、文字和数字"></a>2、文字和数字</h3><hr><p>当语言和词汇多到一定程度，人类仅靠大脑已经及部署所有词汇了。于是，高效记录信息的需求就产生了，这就是文字的起源。</p><p>最早便是使用象形文字。但随着文明的进步，所需的文字越来越多，象形文字无法满足需求。于是，就开始了概念的第一次概括和归类（即一词多意）这种聚类，和如今自然语言处理或者机器学习的聚类有很大的相似性。</p><p>但是，文字按照意思来聚类，会带来一些歧义性。而为了消除歧义（Disambiguation），人们便根据上下文来判断词意，这也是今天自然语言处理时，采用的消歧方法。但是，即使根据上下文也总有做不到确定词意的时候，因此，自然语言处理的消歧，也不可能做到 100%判断出准确的词意</p><p>而在文明发展中，因为地域的原因，各个地方产生了不同的文字，而不同地方的人在交流时，就产生了翻译的需求。</p><p>【重要】翻译这件事之所以能达成，仅仅是因为不同的文字系统在记录信息上的能力是等价的。文字只是信息的载体，不同的文字可以描述相同的信息。这是现代通信的基础。</p><p>罗塞塔石碑带来的启示：1、信息的冗余是信息安全的保障；2、语言的数据，即语料，尤其是双语或者多语的对照语料对翻译至关重要，它是我们从事机器翻译研究的基础。</p><p>数字早期和文字一样，都是承载信息的工具。并不具备任何抽象的含义。</p><p>阿拉伯数字或者说印度数字的革命性，不仅在于它的简洁有效，而且标志着数字和文字的分离。这在客观上，让自然语言的研究和数学在几千年里没有重合的轨迹，而且越走越远。</p><h3 id="3、文字和语言背后的数学"><a href="#3、文字和语言背后的数学" class="headerlink" title="3、文字和语言背后的数学"></a>3、文字和语言背后的数学</h3><hr><p>拼音文字(楔形文字)，起源于两河流域，每个形状不同的楔子实际上是不同的字母。如果把中文的笔画作为字母，它也可以看做是一种拼音文字，只不过是二维的。</p><p>随后拼音文字逐渐发展，古希腊人将字母的拼写和读音紧密结合，使得语言更容易学习。最终成为了今天西方拼音文字的起源——罗马式语言（Roman Languages）</p><p>从象形文字到拼音文字是一个飞跃，因为人类在描述物体的方式上，从物体的外表进化到了抽象的概念，同时不自觉的采用了对信息的编码。同时，文字的编码还非常合理，罗马体系文字中，常用字短，生僻字长，而类似汉字的意形文字也是如此，常用字笔画少，生僻字笔画多。这完全符合信息论中的最短编码原理。</p><p>在古代，书写不是一件容易的事，因此，古人说话和如今的白话差别不大，但书面文字却非常简洁。这非常符合如今信息科学和信息工程中的一些基本原理，即在通行中，如果信道较宽，信息不必压缩就可以直接进行传递；而如果信道较窄，则信息在传递前需要尽可能地压缩。</p><p>犹太人在抄写《圣经》时，为了防止抄错，发明了类似今天计算机和通信中校验码的方法，即每个字母对应一个数字，每行将这些数字相加，获得一个特殊的数字，每抄完一页，对这些数字进行校验，这既能防止抄错，也能在抄错时，快速定位错误位置。这和如今各种校验的原理是相同的。</p>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h2 id=&quot;第一章-文字和语言-vs-数字和信息&quot;&gt;&lt;a href=&quot;#第一章-文字和语言-vs-数字和信息&quot; class=&quot;headerlink&quot; title=&quot;第一章 文字和语言 vs 数字和信息&quot;&gt;&lt;/a&gt;第一章 文字和语言 vs 数字和信息&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;数字、文字、语言都是信息的载体，他们诞生的目的，是为了让信息更好的传播&lt;/p&gt;
    
    </summary>
    
    
      <category term="CS Concept" scheme="https://winyter.github.io/MyBlog/categories/CS-Concept/"/>
    
      <category term="Reading Notes" scheme="https://winyter.github.io/MyBlog/categories/CS-Concept/Reading-Notes/"/>
    
    
      <category term="CS Concept" scheme="https://winyter.github.io/MyBlog/tags/CS-Concept/"/>
    
      <category term="Math" scheme="https://winyter.github.io/MyBlog/tags/Math/"/>
    
      <category term="Reading" scheme="https://winyter.github.io/MyBlog/tags/Reading/"/>
    
      <category term="Notes" scheme="https://winyter.github.io/MyBlog/tags/Notes/"/>
    
  </entry>
  
  <entry>
    <title>CentOS 7x 操作系统安装指南</title>
    <link href="https://winyter.github.io/MyBlog/2020/06/09/centos7x-install-guide/"/>
    <id>https://winyter.github.io/MyBlog/2020/06/09/centos7x-install-guide/</id>
    <published>2020-06-09T15:07:00.000Z</published>
    <updated>2020-07-25T11:15:08.739Z</updated>
    
    <content type="html"><![CDATA[<hr><h3 id="1、选择安装介质"><a href="#1、选择安装介质" class="headerlink" title="1、选择安装介质"></a>1、选择安装介质</h3><a id="more"></a><p>启动服务器，按F11进入BIOS设置，选择启动设备并回车。如下图所示：<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image1.png" alt="image-1.png"></p><p>识别操作系统源文件，选择Install CentOS 7并回车（第一个)：<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image2.png" alt="image-2.png"></p><hr><h3 id="2、配置语言"><a href="#2、配置语言" class="headerlink" title="2、配置语言"></a>2、配置语言</h3><p>配置语言为English<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image3.png" alt="image-3.png"><br>点击右下角的continue。</p><hr><h3 id="3、配置时区"><a href="#3、配置时区" class="headerlink" title="3、配置时区"></a>3、配置时区</h3><p>进入操作系统设计界面<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image4.png" alt="image-4.png"></p><p>配置时区<br>点击选择 <code>DATA &amp; TIME</code>，设置时区为 <code>Asia-Shanghai</code>。<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image5.png" alt="image-5.png"></p><p>配置完成后，点击左上角的done。</p><hr><h3 id="4、选择安装工具包"><a href="#4、选择安装工具包" class="headerlink" title="4、选择安装工具包"></a>4、选择安装工具包</h3><blockquote><p>本节工具包的选择请根据实际需求选择，如果无法确定具体需要使用哪些，可以不做勾选，后期可通过镜像挂载的方式再进行补装</p></blockquote><p>Software selection<br>现举例选择以下的几个服务安装，如下图所示：<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image6.png" alt="image-6.png"></p><p><img src="http://cdn.winyter.cn/centos7x-install-guide-image7.png" alt="image-7.png"></p><p>选择完成后，点击左上角的done。</p><hr><h3 id="5、系统分区"><a href="#5、系统分区" class="headerlink" title="5、系统分区"></a>5、系统分区</h3><blockquote><p>系统分区按照实际需求划分，下面提供一种比较通用的分区方法</p></blockquote><p>Installation Destination</p><ul><li>自定义配置安装，如下图所示：</li></ul><blockquote><p>注意，当磁盘数量较多时，请确认好哪个磁盘作为系统盘，不可装错，另外，生产环境下，建议系统盘配置 RAID1，提高安全性</p></blockquote><p><img src="http://cdn.winyter.cn/centos7x-install-guide-image8.png" alt="image-8.png"></p><ul><li>根据引导进入如下界面，自动创建系统分区。</li></ul><p><img src="http://cdn.winyter.cn/centos7x-install-guide-image9.png" alt="image-9.png"></p><ul><li>修改新增分区</li></ul><blockquote><p>对默认home目录空间进行减少，保证下面的目录空间分配。<br>/boot分区保持默认。<br>将根目录/ 空间增加至100G。<br>新增/usr分区，分配60G。<br>新增/var/log分区，分配60G~100G (视情况而定，若系统盘较大，则该分区给100g；较小则给60g。例如系统盘是600g，/var/log分60G,系统盘是900g，/var/log 分100G）<br>swap分区调整到16G。<br>文件系统选择xfs。</p></blockquote><p><img src="http://cdn.winyter.cn/centos7x-install-guide-image22.png" alt="image-22.png"></p><p>根据以上文字描述的建议进行分配。建议先将默认分好的 <code>/home</code> 的空间给释放出来。<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image10.png" alt="image-10.png"></p><p>接着点 <code>+</code>，按照需求来划分区域。注意填写单位。<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image11.png" alt="image-11.png"></p><p>分好的分区可以参考下图，但具体的分区请按照上面的文字要求进行，这里需注意的是根据盘的大小来划分 <code>/var/log</code> 的大小（600g 系统盘分 60G,900g 系统盘分 100G）。<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image12.png" alt="image-12.png"></p><p>设置完成后，点击 <code>done</code>。弹出框，继续点击 <code>Accept Changer</code>。<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image13.png" alt="imgae-13.pnd"></p><p>配置完成后点击 <code>begin install</code> 开始安装。<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image14.png" alt="image-14.png"></p><hr><h3 id="6、配置用户"><a href="#6、配置用户" class="headerlink" title="6、配置用户"></a>6、配置用户</h3><p>安装过程中可以配置root密码，同时可以添加配置用户<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image15.png" alt="image-15.png"></p><p>修改root用户密码<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image16.png" alt="image-16.png"></p><p>创建用户<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image17.png" alt="image-17.png"></p><hr><h3 id="7、完成安装"><a href="#7、完成安装" class="headerlink" title="7、完成安装"></a>7、完成安装</h3><p>等待安装<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image18.png" alt="image-18.png"><br>等待 20-30 分钟后安装完成。点击右下角的 <code>reboot</code>。</p><p>开机后，进入 <code>licensing</code> 确认界面<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image19.png" alt="image-19.png"></p><p>选择第一项，进入如下界面<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image20.png" alt="image-20.png"></p><p>勾选最下面的 <code>I accept…</code> 的那个选项，点击左上角 <code>done</code>。<br><img src="http://cdn.winyter.cn/centos7x-install-guide-image21.png" alt="image-21.png"></p><p>点击右下角后即可使用操作系统。</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h3 id=&quot;1、选择安装介质&quot;&gt;&lt;a href=&quot;#1、选择安装介质&quot; class=&quot;headerlink&quot; title=&quot;1、选择安装介质&quot;&gt;&lt;/a&gt;1、选择安装介质&lt;/h3&gt;
    
    </summary>
    
    
      <category term="CS Soft" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/"/>
    
      <category term="OS" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/OS/"/>
    
      <category term="Unix" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/OS/Unix/"/>
    
      <category term="Linux" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/OS/Unix/Linux/"/>
    
    
      <category term="OS" scheme="https://winyter.github.io/MyBlog/tags/OS/"/>
    
      <category term="Linux" scheme="https://winyter.github.io/MyBlog/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Homebrew 安装指南</title>
    <link href="https://winyter.github.io/MyBlog/2020/06/09/homebrew-install-guide/"/>
    <id>https://winyter.github.io/MyBlog/2020/06/09/homebrew-install-guide/</id>
    <published>2020-06-09T15:03:51.000Z</published>
    <updated>2020-07-25T11:17:05.885Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>非正式文档，爬坑记录，将安装 Homebrew 的全流程都记录了下来，读完这篇，就能安装顺畅</p></blockquote><hr><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xcode-select --install</span><br><span class="line"></span><br><span class="line">&#x2F;usr&#x2F;bin&#x2F;ruby -e &quot;$(curl -fsSL https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Homebrew&#x2F;install&#x2F;master&#x2F;install)&quot;</span><br></pre></td></tr></table></figure><a id="more"></a><blockquote><p>如果遇到报错：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl: (7) Failed to connect to raw.githubusercontent.com port 443: Connection refused</span><br></pre></td></tr></table></figure><p>换手机热点连接笔记本，无线可能被墙了</p></blockquote><blockquote><p>如果遇到报错：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl: (6) Could not resolve host: raw.githubusercontent.com</span><br></pre></td></tr></table></figure><p>需要在电脑 hosts 文件里添加 IP 主机名映射，默认的 raw.githubusercontent.com 域名的 IP 是错误的</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim &#x2F;etc&#x2F;hosts</span><br><span class="line">添加：</span><br><span class="line">199.232.68.133  githubusercontent.com</span><br><span class="line"># 请使用 https:&#x2F;&#x2F;www.ipaddress.com&#x2F; 查询一下该域名的 IP，这个 IP 不一定是一直不变的</span><br></pre></td></tr></table></figure></blockquote><p>然而，在国内环境下，你会发现，下载速度巨慢，这需要我们把下载源换到国内镜像上</p><p>根据网上的教程，你需要将 brew 的 install 文件下载本地</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -fsSL https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Homebrew&#x2F;install&#x2F;master&#x2F;install &gt;&gt; brew_install</span><br></pre></td></tr></table></figure><p>但是打开这个 brew_install 文件后，你会发现，里面并不是网上教程里所说的那些配置，而是这些东西：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;ruby</span><br><span class="line"></span><br><span class="line">STDERR.print &lt;&lt;EOS</span><br><span class="line">Warning: The Ruby Homebrew installer is now deprecated and has been rewritten in</span><br><span class="line">Bash. Please migrate to the following command:</span><br><span class="line">  &#x2F;bin&#x2F;bash -c &quot;$(curl -fsSL https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Homebrew&#x2F;install&#x2F;master&#x2F;install.sh)&quot;</span><br><span class="line"></span><br><span class="line">EOS</span><br><span class="line"></span><br><span class="line">Kernel.exec &quot;&#x2F;bin&#x2F;bash&quot;, &quot;-c&quot;, &#39;&#x2F;bin&#x2F;bash -c &quot;$(curl -fsSL https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Homebrew&#x2F;install&#x2F;master&#x2F;install.sh)&quot;&#39;</span><br></pre></td></tr></table></figure><p>这时候，你需要仔细的读一读这个文件内容，里面告诉你，原来的那个安装脚本现在已经不使用了，你需要换一个方式去执行，然后，给了你一个新的执行命令，这时候，你只需要把这个命令拿出来，然后把安装脚本下载下来：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -fsSL https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;Homebrew&#x2F;install&#x2F;master&#x2F;install.sh &gt; install.sh</span><br></pre></td></tr></table></figure><p>然后，继续按照网上文档所说的，修改两个参数：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">BREW_REPO &#x3D; &quot;git:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;brew.git&quot;.freeze</span><br><span class="line">CORE_TAP_REPO &#x3D; &quot;git:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;homebrew-core.git&quot;.freeze</span><br></pre></td></tr></table></figure><p>但是，这时候你需要注意，新版的 Homebrew 的安装脚本里，已经没有 <code>CORE_TAP_REPO</code> 这个配置项了，你不需要新增这个配置项，只要把 <code>BREW_REPO</code> 配置修改完即可</p><p>这时，就可以开始执行安装了</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sh install.sh</span><br></pre></td></tr></table></figure><p>注意：由于 Homebrew 默认的更新源还没有换，因此，在安装完成后，会出现如下报错</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x3D;&#x3D;&gt; Tapping homebrew&#x2F;core</span><br><span class="line">Cloning into &#39;&#x2F;usr&#x2F;local&#x2F;Homebrew&#x2F;Library&#x2F;Taps&#x2F;homebrew&#x2F;homebrew-core&#39;...</span><br><span class="line">fatal: unable to access &#39;https:&#x2F;&#x2F;github.com&#x2F;Homebrew&#x2F;homebrew-core&#x2F;&#39;: LibreSSL SSL_read: SSL_ERROR_SYSCALL, errno 54</span><br><span class="line">Error: Failure while executing; &#96;git clone https:&#x2F;&#x2F;github.com&#x2F;Homebrew&#x2F;homebrew-core &#x2F;usr&#x2F;local&#x2F;Homebrew&#x2F;Library&#x2F;Taps&#x2F;homebrew&#x2F;homebrew-core&#96; exited with 128.</span><br><span class="line">Error: Failure while executing; &#96;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;brew tap homebrew&#x2F;core&#96; exited with 1.</span><br><span class="line">Failed during: &#x2F;usr&#x2F;local&#x2F;bin&#x2F;brew update --force</span><br></pre></td></tr></table></figure><p>或者，很长时间，卡在<code>Cloning into &#39;/usr/local/Homebrew/Library/Taps/homebrew/homebrew-core&#39;...</code>这句话上</p><p>这时，继续执行以下语句：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone git:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;homebrew-core.git&#x2F; &#x2F;usr&#x2F;local&#x2F;Homebrew&#x2F;Library&#x2F;Taps&#x2F;homebrew&#x2F;homebrew-core --depth&#x3D;1</span><br><span class="line"></span><br><span class="line">git clone git:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;homebrew-cask.git&#x2F; &#x2F;usr&#x2F;local&#x2F;Homebrew&#x2F;Library&#x2F;Taps&#x2F;caskroom&#x2F;homebrew-cask --depth&#x3D;1</span><br></pre></td></tr></table></figure><p>至此，安装完成，下面开始替换更新源。</p><p>目前国内主流有两种源可以选择，中科大镜像和清华镜像，下面也会给出两种镜像的替换方法，任选其一即可</p><ul><li>中科大镜像(方法缘于广大网友)：</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 替换默认源</span><br><span class="line">cd &quot;$(brew --repo)&quot;</span><br><span class="line">git remote set-url origin https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;brew.git</span><br><span class="line"> </span><br><span class="line"># 替换核心仓库源</span><br><span class="line">cd &quot;$(brew --repo)&#x2F;Library&#x2F;Taps&#x2F;homebrew&#x2F;homebrew-core&quot;</span><br><span class="line">git remote set-url origin https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;homebrew-core.git</span><br><span class="line"></span><br><span class="line"># 替换 cask 软件仓库（提供 macOS 应用和大型二进制文件）</span><br><span class="line">cd &quot;$(brew --repo)&#x2F;Library&#x2F;Taps&#x2F;caskroom&#x2F;homebrew-cask&quot;</span><br><span class="line">git remote set-url origin https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;homebrew-cask.git</span><br><span class="line"></span><br><span class="line"># brew 更新</span><br><span class="line">brew update</span><br><span class="line"></span><br><span class="line"># 替换 Bottles 源（Homebrew 预编译二进制软件包）</span><br><span class="line">echo &#39;export HOMEBREW_BOTTLE_DOMAIN&#x3D;https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;homebrew-bottles&#39; &gt;&gt; ~&#x2F;.bash_profile</span><br><span class="line">source ~&#x2F;.bash_profile</span><br><span class="line"></span><br><span class="line"># 检查</span><br><span class="line">brew doctor</span><br></pre></td></tr></table></figure><ul><li>清华镜像(源自：<a href="https://mirror.tuna.tsinghua.edu.cn/help/homebrew/" target="_blank" rel="noopener">清华镜像官方使用说明</a>)<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git -C &quot;$(brew --repo)&quot; remote set-url origin https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;git&#x2F;homebrew&#x2F;brew.git</span><br><span class="line"></span><br><span class="line">git -C &quot;$(brew --repo homebrew&#x2F;core)&quot; remote set-url origin https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;git&#x2F;homebrew&#x2F;homebrew-core.git</span><br><span class="line">git -C &quot;$(brew --repo homebrew&#x2F;cask)&quot; remote set-url origin https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;git&#x2F;homebrew&#x2F;homebrew-cask.git</span><br><span class="line">git -C &quot;$(brew --repo homebrew&#x2F;cask-fonts)&quot; remote set-url origin https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;git&#x2F;homebrew&#x2F;homebrew-cask-fonts.git</span><br><span class="line">git -C &quot;$(brew --repo homebrew&#x2F;cask-drivers)&quot; remote set-url origin https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;git&#x2F;homebrew&#x2F;homebrew-cask-drivers.git</span><br></pre></td></tr></table></figure></li></ul><p>参考：</p><ul><li><a href="https://blog.csdn.net/weixin_34067980/article/details/88008241" target="_blank" rel="noopener">Mac HomeBrew国内镜像安装方法</a></li><li><a href="https://www.jianshu.com/p/5822d24a651e" target="_blank" rel="noopener">Mac下使用国内镜像安装Homebrew</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;非正式文档，爬坑记录，将安装 Homebrew 的全流程都记录了下来，读完这篇，就能安装顺畅&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;xcode-select --install&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#x2F;usr&amp;#x2F;bin&amp;#x2F;ruby -e &amp;quot;$(curl -fsSL https:&amp;#x2F;&amp;#x2F;raw.githubusercontent.com&amp;#x2F;Homebrew&amp;#x2F;install&amp;#x2F;master&amp;#x2F;install)&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="CS Soft" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/"/>
    
      <category term="Homebrew" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Homebrew/"/>
    
    
      <category term="MacOS" scheme="https://winyter.github.io/MyBlog/tags/MacOS/"/>
    
      <category term="Tools" scheme="https://winyter.github.io/MyBlog/tags/Tools/"/>
    
  </entry>
  
  <entry>
    <title>基于 Ambari 的大数据集群安装指导——篇十六：Ambari 管理</title>
    <link href="https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-16-ambari-manage-md/"/>
    <id>https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-16-ambari-manage-md/</id>
    <published>2020-05-31T09:57:46.000Z</published>
    <updated>2020-07-25T11:14:44.348Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="1、Ambari-用户管理"><a href="#1、Ambari-用户管理" class="headerlink" title="1、Ambari 用户管理"></a>1、Ambari 用户管理</h2><a id="more"></a><p>使用默认用户 <code>admin/admin</code> 登录 Ambari 页面，点击用户下的 <code>Manage Ambari</code> 按钮，进入 Ambari 管理界面。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image232.png" alt="image-232.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image233.png" alt="image-233.png"></p><p>Manage Users / Groups 模块可以创建 ambari 用户和用户组，并为用户赋予权限：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image234.png" alt="image-234.png"></p><hr><h2 id="2、View-管理"><a href="#2、View-管理" class="headerlink" title="2、View 管理"></a>2、View 管理</h2><p>用于扩展 Ambari Web UI 中的框架。点击 Views 进入页面：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image235.png" alt="image-235.png"></p><p>创建的views还可以通过主页中的视图菜单查看：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image236.png" alt="image-236.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image237.png" alt="image-237.png"></p><hr><h2 id="3、Hadoop集群管理"><a href="#3、Hadoop集群管理" class="headerlink" title="3、Hadoop集群管理"></a>3、Hadoop集群管理</h2><p>进入仪表盘，可以管理安装的集群:<br><img src="http://cdn.winyter.cn/ambari-install-guide_image238.png" alt="image-238.png"></p><p>Hadoop 集群管理包括：</p><ul><li>集群扩容（新增机器）</li><li>添加、删除服务<br>添加服务后，需要重启 ambari-server。</li><li>启动、停止服务</li><li>修改配置</li><li>监控数据并告警</li><li>自定义操作</li></ul><p>点击 Hosts，可以分别按照服务、机器进行管理：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image239.png" alt="image-239.png"></p><hr><h2 id="4、Ambari-清理"><a href="#4、Ambari-清理" class="headerlink" title="4、Ambari 清理"></a>4、Ambari 清理</h2><blockquote><p>注意：Ambari清理需要对所有的机器都执行，不是只在主机上。</p></blockquote><p>如果通过 ambari 安装 Hadoop 集群后，想重新再来一次的话，需要清理集群。<br>1、通过 ambari 将集群中的所用组件都关闭，如果关闭不了，直接 <code>kill -9 XXX</code>。</p><p>2、关闭 ambari-server，ambari-agent</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ambari-server stop </span><br><span class="line">ambari-agent stop</span><br></pre></td></tr></table></figure><p>3、卸载安装的软件（当出现 <code>is this ok</code> 的提示的时候输入 <code>y</code> 即可）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum remove hadoop_2* hdp-select* ranger_2* zookeeper_* bigtop* atlas-metadata* ambari* postgresql spark* slider* storm* snappy*</span><br></pre></td></tr></table></figure><p>4、查看是否还有没有卸载的</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum list | grep @HDP</span><br></pre></td></tr></table></figure><p>如果有，继续通过 <code>yum remove XXX</code> 卸载</p><p>5、删除 postgresql 的数据（如果使用其他数据库，可跳过此步骤）<br>postgresql 软件卸载后，其数据还保留在硬盘中，需要把这部分数据删除掉，如果不删除掉，重新安装 ambari-server 后，有可能还应用以前的安装数据，而这些数据时错误数据，所以需要删除掉。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -rf &#x2F;var&#x2F;lib&#x2F;pgsql</span><br></pre></td></tr></table></figure><p>6、删除用户和对应文件夹<br>（复制下面表格全部的命令，在 xshell 界面中直接粘贴就可以全部执行。）<br>ambari 安装 hadoop 集群会创建一些用户，清除集群时有必要清除这些用户，并删除对应的文件夹。这样做可以避免集群运行时出现的文件访问权限错误的问题。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -rf &#x2F;home&#x2F;atlas</span><br><span class="line">rm -rf &#x2F;home&#x2F;accumulo </span><br><span class="line">rm -rf &#x2F;home&#x2F;hbase </span><br><span class="line">rm -rf &#x2F;home&#x2F;hive </span><br><span class="line">rm -rf &#x2F;home&#x2F;oozie </span><br><span class="line">rm -rf &#x2F;home&#x2F;storm </span><br><span class="line">rm -rf &#x2F;home&#x2F;yarn </span><br><span class="line">rm -rf &#x2F;home&#x2F;ambari-qa </span><br><span class="line">rm -rf &#x2F;home&#x2F;falcon </span><br><span class="line">rm -rf &#x2F;home&#x2F;hcat </span><br><span class="line">rm -rf &#x2F;home&#x2F;kafka </span><br><span class="line">rm -rf &#x2F;home&#x2F;mahout </span><br><span class="line">rm -rf &#x2F;home&#x2F;spark </span><br><span class="line">rm -rf &#x2F;home&#x2F;tez </span><br><span class="line">rm -rf &#x2F;home&#x2F;zookeeper </span><br><span class="line">rm -rf &#x2F;home&#x2F;flume </span><br><span class="line">rm -rf &#x2F;home&#x2F;hdfs</span><br><span class="line">rm -rf &#x2F;hdfs&#x2F;hadoop </span><br><span class="line">rm -rf &#x2F;home&#x2F;knox </span><br><span class="line">rm -rf &#x2F;home&#x2F;mapred </span><br><span class="line">rm -rf &#x2F;home&#x2F;sqoop</span><br></pre></td></tr></table></figure><p>7、删除ambari遗留数据</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -rf &#x2F;var&#x2F;lib&#x2F;ambari*</span><br><span class="line">rm -rf &#x2F;usr&#x2F;lib&#x2F;python2.6&#x2F;site-packages&#x2F;ambari_* </span><br><span class="line">rm -rf &#x2F;usr&#x2F;lib&#x2F;python2.6&#x2F;site-packages&#x2F;resource_management </span><br><span class="line">rm -rf &#x2F;usr&#x2F;lib&#x2F;ambri-*</span><br></pre></td></tr></table></figure><p>8、删除其他hadoop组件遗留数据</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -rf &#x2F;etc&#x2F;falcon</span><br><span class="line">rm -rf &#x2F;etc&#x2F;knox</span><br><span class="line">rm -rf &#x2F;etc&#x2F;hive-webhcat</span><br><span class="line">rm -rf &#x2F;etc&#x2F;kafka</span><br><span class="line">rm -rf &#x2F;etc&#x2F;slider</span><br><span class="line">rm -rf &#x2F;etc&#x2F;storm-slider-client</span><br><span class="line">rm -rf &#x2F;etc&#x2F;spark</span><br><span class="line">rm -rf &#x2F;var&#x2F;run&#x2F;spark</span><br><span class="line">rm -rf &#x2F;var&#x2F;run&#x2F;hadoop</span><br><span class="line">rm -rf &#x2F;var&#x2F;run&#x2F;hbase</span><br><span class="line">rm -rf &#x2F;var&#x2F;run&#x2F;zookeeper</span><br><span class="line">rm -rf &#x2F;var&#x2F;run&#x2F;flume</span><br><span class="line">rm -rf &#x2F;var&#x2F;run&#x2F;storm</span><br><span class="line">rm -rf &#x2F;var&#x2F;run&#x2F;webhcat</span><br><span class="line">rm -rf &#x2F;var&#x2F;run&#x2F;hadoop-yarn</span><br><span class="line">rm -rf &#x2F;var&#x2F;run&#x2F;hadoop-mapreduce</span><br><span class="line">rm -rf &#x2F;var&#x2F;run&#x2F;kafka</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;hadoop</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;hbase</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;flume</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;storm</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;hadoop-yarn</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;hadoop-mapreduce</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;knox</span><br><span class="line">rm -rf &#x2F;usr&#x2F;lib&#x2F;flume</span><br><span class="line">rm -rf &#x2F;usr&#x2F;lib&#x2F;storm</span><br><span class="line">rm -rf &#x2F;var&#x2F;lib&#x2F;hive</span><br><span class="line">rm -rf &#x2F;var&#x2F;lib&#x2F;oozie</span><br><span class="line">rm -rf &#x2F;var&#x2F;lib&#x2F;flume</span><br><span class="line">rm -rf &#x2F;var&#x2F;lib&#x2F;hadoop-hdfs</span><br><span class="line">rm -rf &#x2F;var&#x2F;lib&#x2F;knox</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;hive</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;oozie</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;zookeeper</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;falcon</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;webhcat</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;spark</span><br><span class="line">rm -rf &#x2F;var&#x2F;tmp&#x2F;oozie</span><br><span class="line">rm -rf &#x2F;tmp&#x2F;ambari-qa</span><br><span class="line">rm -rf &#x2F;var&#x2F;hadoop</span><br><span class="line">rm -rf &#x2F;hadoop&#x2F;falcon</span><br><span class="line">rm -rf &#x2F;tmp&#x2F;hadoop</span><br><span class="line">rm -rf &#x2F;tmp&#x2F;hadoop-hdfs</span><br><span class="line">rm -rf &#x2F;usr&#x2F;hdp</span><br><span class="line">rm -rf &#x2F;usr&#x2F;hadoop</span><br><span class="line">rm -rf &#x2F;opt&#x2F;hadoop</span><br><span class="line">rm -rf &#x2F;opt&#x2F;hadoop2</span><br><span class="line">rm -rf &#x2F;tmp&#x2F;hadoop</span><br><span class="line">rm -rf &#x2F;var&#x2F;hadoop</span><br><span class="line">rm -rf &#x2F;hadoop</span><br><span class="line">rm -rf &#x2F;etc&#x2F;ambari-metrics-collector</span><br><span class="line">rm -rf &#x2F;etc&#x2F;ambari-metrics-monitor</span><br><span class="line">rm -rf &#x2F;var&#x2F;run&#x2F;ambari-metrics-collector</span><br><span class="line">rm -rf &#x2F;var&#x2F;run&#x2F;ambari-metrics-monitor</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;ambari-metrics-collector</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;ambari-metrics-monitor</span><br><span class="line">rm -rf &#x2F;var&#x2F;lib&#x2F;hadoop-yarn</span><br><span class="line">rm -rf &#x2F;var&#x2F;lib&#x2F;hadoop-mapreduce</span><br><span class="line">rm -rf &#x2F;var&#x2F;lib&#x2F;hadoop-hdfs</span><br><span class="line">rm -rf &#x2F;etc&#x2F;hadoop</span><br><span class="line">rm -rf &#x2F;etc&#x2F;hadoop-httpfs</span><br><span class="line"></span><br><span class="line">yum remove zookeeper*</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;zookeeper</span><br><span class="line">rm -rf &#x2F;etc&#x2F;zookeeper</span><br><span class="line">rm -rf &#x2F;var&#x2F;run&#x2F;zookeeper</span><br><span class="line">rm -rf zookeeper-client</span><br><span class="line">rm -rf zookeeper-server</span><br><span class="line">rm -rf zookeeper-server-cleanup</span><br><span class="line">userdel -r zookeeper</span><br><span class="line">find &#x2F; -name zookeeper</span><br></pre></td></tr></table></figure><p>最后 <code>find</code>，输入这条命令后如果还有看到文件夹残留，则删除该文件夹。</p><p>9、删除数据（data01-data12的路径需要根据实际路径修改）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -rf &#x2F;usr&#x2F;hdp&#x2F;*</span><br><span class="line">rm -rf &#x2F;data01&#x2F;*</span><br><span class="line">rm -rf &#x2F;data02&#x2F;*</span><br><span class="line">rm -rf &#x2F;data03&#x2F;*</span><br><span class="line">rm -rf &#x2F;data04&#x2F;*</span><br><span class="line">rm -rf &#x2F;data06&#x2F;*</span><br><span class="line">rm -rf &#x2F;data07&#x2F;*</span><br><span class="line">rm -rf &#x2F;data08&#x2F;*</span><br><span class="line">rm -rf &#x2F;data09&#x2F;*</span><br><span class="line">rm -rf &#x2F;data10&#x2F;*</span><br><span class="line">rm -rf &#x2F;data11&#x2F;*</span><br><span class="line">rm -rf &#x2F;data12&#x2F;*</span><br><span class="line">rm -rf &#x2F;hadoop&#x2F;*</span><br></pre></td></tr></table></figure><p>10、清理 yum 数据源</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum clean all</span><br></pre></td></tr></table></figure><p>11、删除ambari数据库<br>登录到MySQL执行以下语句：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">drop DATABASE ambari;</span><br></pre></td></tr></table></figure><p>12、清理smartsense</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum remove smartsense-hst</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;smartsense</span><br><span class="line"></span><br><span class="line">然后再次使用yum命令安装：</span><br><span class="line">yum install smartsense-hst</span><br></pre></td></tr></table></figure><p>此外，还需要删除在 <code>/tmp</code> 文件夹下的相关文件夹，如下图所示。</p><blockquote><p>hsperfdata_rhino和hsperfdata_root文件夹不能删除，其他的文件夹都要删除。</p></blockquote><p><img src="http://cdn.winyter.cn/ambari-install-guide_image241.png" alt="image-241.png"></p><p>命令如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node1 home]$ cd &#x2F;tmp</span><br></pre></td></tr></table></figure><p>然后执行如下脚本：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -rf hbase-hbase&#x2F;</span><br><span class="line">rm -rf hsperfdata_elastic&#x2F;</span><br><span class="line">rm -rf hsperfdata_hbase&#x2F;</span><br><span class="line">rm -rf hsperfdata_hdfs&#x2F;</span><br><span class="line">rm -rf hsperfdata_impala&#x2F;</span><br><span class="line">rm -rf hsperfdata_kafka&#x2F;</span><br><span class="line">rm -rf hsperfdata_redis&#x2F;</span><br><span class="line">rm -rf hsperfdata_testt&#x2F;</span><br><span class="line">rm -rf hsperfdata_yarn&#x2F;</span><br><span class="line">rm -rf hsperfdata_zookeeper&#x2F;</span><br></pre></td></tr></table></figure><p>执行完以上脚本后最好自己检查一下是否删除对应的文件。</p><blockquote><p>除此之外还需要删除home目录下面除了rhino文件夹之外的其他所有文件夹。</p></blockquote><hr><h2 id="5、Ambari-HDFS-HA-回滚"><a href="#5、Ambari-HDFS-HA-回滚" class="headerlink" title="5、Ambari HDFS-HA 回滚"></a>5、Ambari HDFS-HA 回滚</h2><blockquote><p>正常情况下，不需要执行该步骤，只有还是 hdfs 升级高可用失败时才需要执行回滚操作。</p></blockquote><p>1、查看hdfs的信息</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -u admin:admin -H &quot;X-Requested-By: ambari&quot; -X GET http:&#x2F;&#x2F;172.168.1.1:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;mycluster&#x2F;services&#x2F;HDFS</span><br></pre></td></tr></table></figure><p>172.168.1.1 为 Ambari Server 的机器 IP（端口默认为 8080）；mycluster 为 cluster 名字，从 ambari 库的 clusters 表中查询，字段是 cluster_name ；HDFS 为 Service 的名字，从 ambari 库的 clusterservices 表中查询，字段是 service_name。</p><p>2、停止hdfs</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -u admin:admin -H &quot;X-Requested-By: ambari&quot; -X PUT -d &#39;&#123;&quot;RequestInfo&quot;: &#123;&quot;context&quot;:&quot;Stop Service&quot;&#125;,&quot;Body&quot;:&#123;&quot;ServiceInfo&quot;:&#123;&quot;state&quot;:&quot;INSTALLED&quot;&#125;&#125;&#125;&#39; http:&#x2F;&#x2F;172.168.1.1:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;mycluster&#x2F;services&#x2F;HDFS</span><br></pre></td></tr></table></figure><p>3、查看各主机的组件角色<br>查看 NAMENODE</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -u admin:admin -i http:&#x2F;&#x2F;172.168.1.1:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;mycluster&#x2F;host_components?HostRoles&#x2F;component_name&#x3D;NAMENODE</span><br></pre></td></tr></table></figure><p>查看 SECONDARY_NAMENODE</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -u admin:admin -i http:&#x2F;&#x2F;172.168.1.1:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;mycluster&#x2F;host_components?HostRoles&#x2F;component_name&#x3D;SECONDARY_NAMENODE</span><br></pre></td></tr></table></figure><p>查看JOURNALNODE</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -u admin:admin -i http:&#x2F;&#x2F;172.168.1.1:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;mycluster&#x2F;host_components?HostRoles&#x2F;component_name&#x3D;JOURNALNODE</span><br></pre></td></tr></table></figure><p>查看ZKFC</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -u admin:admin -i http:&#x2F;&#x2F;172.168.1.1:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;mycluster&#x2F;host_components?HostRoles&#x2F;component_name&#x3D;ZKFC</span><br></pre></td></tr></table></figure><p>4、删除zkfc</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -u admin:admin -H &quot;X-Requested-By: ambari&quot; -X DELETE http:&#x2F;&#x2F;172.168.1.1:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;mycluster&#x2F;hosts&#x2F;node2&#x2F;host_components&#x2F;ZKFC</span><br><span class="line"></span><br><span class="line">curl -u admin:admin -H &quot;X-Requested-By: ambari&quot; -X DELETE http:&#x2F;&#x2F;172.168.1.1:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;mycluster&#x2F;hosts&#x2F;node3&#x2F;host_components&#x2F;ZKFC</span><br></pre></td></tr></table></figure><p>node2 和 node3 是安装 zkfc 机器的 hostname。</p><p>5、启用SECONDARY_NAMENODE</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -u admin:admin -H &quot;X-Requested-By: ambari&quot; -X POST -d &#39;&#123;&quot;host_components&quot; : [&#123;&quot;HostRoles&quot;:&#123;&quot;component_name&quot;:&quot;SECONDARY_NAMENODE&quot;&#125;&#125;] &#125;&#39; http:&#x2F;&#x2F;172.168.1.1:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;mycluster&#x2F;hosts?Hosts&#x2F;host_name&#x3D;node2</span><br><span class="line"></span><br><span class="line">curl -u admin:admin -H &quot;X-Requested-By: ambari&quot; -X PUT -d &#39;&#123;&quot;RequestInfo&quot;:&#123;&quot;context&quot;:&quot;Enable Secondary NameNode&quot;&#125;,&quot;Body&quot;:&#123;&quot;HostRoles&quot;:&#123;&quot;state&quot;:&quot;INSTALLED&quot;&#125;&#125;&#125;&#39; http:&#x2F;&#x2F;172.168.1.1:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;mycluster&#x2F;hosts&#x2F;node2&#x2F;host_components&#x2F;SECONDARY_NAMENODE</span><br><span class="line"></span><br><span class="line">curl -u admin:admin -H &quot;X-Requested-By: ambari&quot; -X GET &quot;http:&#x2F;&#x2F;172.168.1.1:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;cluster&#x2F;host_components?HostRoles&#x2F;component_name&#x3D;SECONDARY_NAMENODE&amp;fields&#x3D;HostRoles&#x2F;state&quot;</span><br></pre></td></tr></table></figure><p>node2 是安装 secondary_namenode 机器的 hostname</p><p>6、删除 journalnode</p><p>先查看哪些机器上安装了 journalnode:</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -u admin:admin -H &quot;X-Requested-By: ambari&quot; -X GET http:&#x2F;&#x2F;10.10.111.11:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;&#x2F;rhino&#x2F;host_components?HostRoles&#x2F;component_name&#x3D;JOURNALNODE</span><br></pre></td></tr></table></figure><p>删除journalnode：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -u admin:admin -H &quot;X-Requested-By: ambari&quot; -X DELETE http:&#x2F;&#x2F;10.10.111.11:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;rhino&#x2F;hosts&#x2F;rhino011&#x2F;host_components&#x2F;JOURNALNODE</span><br><span class="line"></span><br><span class="line">curl -u admin:admin -H &quot;X-Requested-By: ambari&quot; -X DELETE http:&#x2F;&#x2F;10.10.111.11:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;rhino&#x2F;hosts&#x2F;rhino012&#x2F;host_components&#x2F;JOURNALNODE</span><br><span class="line"></span><br><span class="line">curl -u admin:admin -H &quot;X-Requested-By: ambari&quot; -X DELETE http:&#x2F;&#x2F;10.10.111.11:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;rhino&#x2F;hosts&#x2F;rhino051&#x2F;host_components&#x2F;JOURNALNODE</span><br></pre></td></tr></table></figure><p>7、删除额外的 namenode<br>查看 namenode：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -u admin:admin -H &quot;X-Requested-By: ambari&quot; -X GET http:&#x2F;&#x2F;10.10.111.11:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;rhino&#x2F;host_components?HostRoles&#x2F;component_name&#x3D;NAMENODE</span><br></pre></td></tr></table></figure><p>删除 namenode：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -u admin:admin -H &quot;X-Requested-By: ambari&quot; -X DELETE http:&#x2F;&#x2F;10.10.111.11:8080&#x2F;api&#x2F;v1&#x2F;clusters&#x2F;rhino&#x2F;hosts&#x2F;rhino012&#x2F;host_components&#x2F;NAMENODE</span><br></pre></td></tr></table></figure><p>8、恢复 hdfs 配置</p><p>在 ambari 的页面上将 hdfs 的配置版本信息改为 HA 之前的版本</p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image240.png" alt="image-240.png"></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h2 id=&quot;1、Ambari-用户管理&quot;&gt;&lt;a href=&quot;#1、Ambari-用户管理&quot; class=&quot;headerlink&quot; title=&quot;1、Ambari 用户管理&quot;&gt;&lt;/a&gt;1、Ambari 用户管理&lt;/h2&gt;
    
    </summary>
    
    
      <category term="CS Soft" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/"/>
    
      <category term="Server" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/"/>
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/Ambari/"/>
    
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/tags/Ambari/"/>
    
      <category term="Bigdata" scheme="https://winyter.github.io/MyBlog/tags/Bigdata/"/>
    
  </entry>
  
  <entry>
    <title>基于 Ambari 的大数据集群安装指导——篇十五：手动安装 Kafka Manager</title>
    <link href="https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-15-install-kafka-manager-md/"/>
    <id>https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-15-install-kafka-manager-md/</id>
    <published>2020-05-31T09:55:31.000Z</published>
    <updated>2020-07-25T11:14:40.027Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h2><p>Kafka Manager 可用于监控和管理 kafka 集群。</p><a id="more"></a><p>主要作用有：</p><ul><li>便捷的监控集群状态（topics，consumers，offsets，brokers，副本分布，分区分布）；</li><li>根据自定义配置创建 topic；</li><li>删除 topic，但是前提是配置 kafka 的 delete.topic.enable=true；</li><li>增加已存在 topic 的分区；</li><li>更新已存在 topic 的配置等等。</li></ul><hr><h2 id="2、修改-Kafka-配置【在每个-Kafka-broker-节点的-kafka-用户下执行】"><a href="#2、修改-Kafka-配置【在每个-Kafka-broker-节点的-kafka-用户下执行】" class="headerlink" title="2、修改 Kafka 配置【在每个 Kafka broker 节点的 kafka 用户下执行】"></a>2、修改 Kafka 配置【在每个 Kafka broker 节点的 kafka 用户下执行】</h2><ul><li><p>修改 kafka 启动文件：<code>kafka-server-start.sh</code> 文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[kafka@node1 ~]$ vim &#x2F;home&#x2F;kafka&#x2F;kafka-1.1.0&#x2F;bin&#x2F;kafka-server-start.sh</span><br><span class="line"></span><br><span class="line">#在 EXTRA_ARGS&#x3D;$&#123;EXTRA_ARGS-&#39;-name kafkaServer -loggc&#39;&#125;上面添加以下内容，如果已存在，修改端口号即可</span><br><span class="line">export JMX_PORT&#x3D;&quot;8999&quot;</span><br></pre></td></tr></table></figure><blockquote><p>注意：1.端口8999不能被占用；2.所有安装kafka的机器都需要修改</p></blockquote></li><li><p>重启kafka<br>登录 ambari 页面，先点击 <code>Kafka</code>，然后点击右上角 <code>ACTION</code> 里的 <code>Restart All</code>。</p><blockquote><p>1.端口 8999 是监听 kafka 的。修改完该配置项后，需要重启 kafka，8999 端口才会被监听。<br>2.该端口进程不要删。如果不小心删掉了，需要重启一下 kafka。</p></blockquote></li></ul><hr><h2 id="3、安装-Kafka-Manager【rhino-用户下执行】"><a href="#3、安装-Kafka-Manager【rhino-用户下执行】" class="headerlink" title="3、安装 Kafka Manager【rhino 用户下执行】"></a>3、安装 Kafka Manager【rhino 用户下执行】</h2><p>先将 <code>kafka-manager-1.3.3.4.zip</code> 安装包上传至任意一台服务器 <code>/home/rhino</code> 目录下。（建议避开管理节点的机器）<br>解压安装包</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@node1 ~]$ cd &#x2F;home&#x2F;rhino</span><br><span class="line">[rhino@node1 ~]$ unzip kafka-manager-1.3.3.4.zip</span><br></pre></td></tr></table></figure><p>修改配置文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@node1 ~]$ vim &#x2F;home&#x2F;rhino&#x2F;kafka-manager-1.3.3.4&#x2F;conf&#x2F;application.conf</span><br><span class="line"></span><br><span class="line">修改以下内容：增加所有zookeeper的地址</span><br><span class="line">kafka-manager.zkhosts&#x3D;&quot;node1:2181,node2:2181,node3:2181&quot;</span><br></pre></td></tr></table></figure><p>启动kafka-manager</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@node1 ~]$ cd &#x2F;home&#x2F;rhino&#x2F;kafka-manager-1.3.3.4</span><br><span class="line">[rhino@node1 ~]$ nohup bin&#x2F;kafka-manager -Dconfig.file&#x3D;conf&#x2F;application.conf -Dhttp.port&#x3D;9000 &amp;</span><br></pre></td></tr></table></figure><blockquote><p>1.9000是kafka-manager的默认端口，不要修改；2.确保9000端口没有被占用。</p></blockquote><hr><h2 id="4、配置kafka-manager"><a href="#4、配置kafka-manager" class="headerlink" title="4、配置kafka manager"></a>4、配置kafka manager</h2><p>登录管理界面 <code>http://172.168.1.1:9000</code>，对 kafka manager 进行配置。<br>增加集群<br>点击 <code>Cluster</code> → <code>Add Cluster</code><br><img src="http://cdn.winyter.cn/ambari-install-guide_image230.png" alt="image-230.png"></p><p>配置集群信息<br>修改图中红圈几处，点击保存即可。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image231.png" alt="image-231.png"></p><p>配置完成后，即可使用 Kafka Manager 进行管理操作</p><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h2 id=&quot;1、简介&quot;&gt;&lt;a href=&quot;#1、简介&quot; class=&quot;headerlink&quot; title=&quot;1、简介&quot;&gt;&lt;/a&gt;1、简介&lt;/h2&gt;&lt;p&gt;Kafka Manager 可用于监控和管理 kafka 集群。&lt;/p&gt;
    
    </summary>
    
    
      <category term="CS Soft" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/"/>
    
      <category term="Server" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/"/>
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/Ambari/"/>
    
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/tags/Ambari/"/>
    
      <category term="Bigdata" scheme="https://winyter.github.io/MyBlog/tags/Bigdata/"/>
    
  </entry>
  
  <entry>
    <title>基于 Ambari 的大数据集群安装指导——篇十四：手动安装Spark</title>
    <link href="https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-14-install-spark-md/"/>
    <id>https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-14-install-spark-md/</id>
    <published>2020-05-31T09:54:08.000Z</published>
    <updated>2020-07-25T11:14:34.624Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="1、Spark-简介"><a href="#1、Spark-简介" class="headerlink" title="1、Spark 简介"></a>1、Spark 简介</h2><p>Apache Spark 是一个分布式计算框架，旨在简化运行于计算机集群上的并行程序的编写。该框架对资源调度，任务的提交、执行和跟踪，节点间的通信以及数据并行处理的内在底层操作都进行了抽象。它提供了一个更高级别的 API 用于处理分布式数据。从这方面说，它与 Apache Hadoop 等分布式处理框架类似。但在底层架构上，Spark 与它们有所不同。</p><a id="more"></a><p>运行模式上，Spark 支持四种运行模式：</p><ul><li>本地单机模式：所有 Spark 进程都运行在同一个 Java 虚拟机（Java Vitural Machine，JVM）中。</li><li>集群单机模式：使用 Spark 自己内置的任务调度框架。</li><li>基于 Mesos：Mesos 是一个流行的开源集群计算框架。</li><li>基于 YARN：即 Hadoop 2，它是一个与 Hadoop 关联的集群计算和资源调度框架。</li></ul><p>本文将讲述基于 YARN 的 Spark 分布式集群部署指导。</p><blockquote><p>注意：本次安装以3台节点为例，其中 node1 为主节点，node2、node3 为 slaves 节点，本次安装采取主节点安装配置，然后分发到各个 slaves 的方式来进行部署</p></blockquote><hr><h2 id="2、主节点安装-Scala【在-Spark-主节点的-rhino-用户下执行】"><a href="#2、主节点安装-Scala【在-Spark-主节点的-rhino-用户下执行】" class="headerlink" title="2、主节点安装 Scala【在 Spark 主节点的 rhino 用户下执行】"></a>2、主节点安装 Scala【在 Spark 主节点的 rhino 用户下执行】</h2><p>以 rhino 用户安装，将安装包 <code>scala-2.11.7.tar.gz</code> 上传至 <code>/home/rhino</code> 目录下。</p><p>解压 <code>scala-2.11.7.tar.gz</code></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@node1 ~]$ cd &#x2F;home&#x2F;rhino</span><br><span class="line">[rhino@node1 ~]$ tar -zxvf scala-2.11.7.tar.gz</span><br></pre></td></tr></table></figure><hr><h2 id="3、主节点安装-Spark-【在-Spark-主节点的-rhino-用户下执行】"><a href="#3、主节点安装-Spark-【在-Spark-主节点的-rhino-用户下执行】" class="headerlink" title="3、主节点安装 Spark 【在 Spark 主节点的 rhino 用户下执行】"></a>3、主节点安装 Spark 【在 Spark 主节点的 rhino 用户下执行】</h2><p>以 rhino 用户安装，将安装包 <code>spark-2.2.0-bin-hadoop2.6.tgz</code> 上传至 <code>/home/rhino</code> 目录下。<br>这里以安装3台为例。</p><p>解压 spark 安装包</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@node1 ~]$ cd &#x2F;home&#x2F;rhino</span><br><span class="line">[rhino@node1 ~]$tar -zxvf spark-2.2.0-bin-hadoop2.6.tgz</span><br></pre></td></tr></table></figure><p>修改环境变量</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@node1 ~]$ vim .bashrc</span><br></pre></td></tr></table></figure><p>添加如下内容（如果有已经添加的，可以不需要再添加；实际路径根据实际情况填写）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;&#x2F;home&#x2F;rhino&#x2F;jdk1.8.0_181</span><br><span class="line">export SCALA_HOME&#x3D;&#x2F;home&#x2F;rhino&#x2F;scala-2.11.7</span><br><span class="line">export LD_LIBRARY_PATH&#x3D;&#x2F;home&#x2F;rhino&#x2F;mysql-5.6.25-linux-x86_64&#x2F;lib:$LD_LIBRARY_PATH</span><br><span class="line">export SPARK_HOME&#x3D;&#x2F;home&#x2F;rhino&#x2F;spark-2.2.0-bin-hadoop2.6</span><br><span class="line">export SPARK_PID_DIR&#x3D;&#x2F;home&#x2F;rhino&#x2F;pids</span><br><span class="line">export HADOOP_HOME&#x3D;&#x2F;usr&#x2F;hdp&#x2F;2.6.3.0-235&#x2F;hadoop</span><br><span class="line">export PATH&#x3D;$JAVA_HOME&#x2F;bin:$SCALA_HOME&#x2F;bin:$SPARK_HOME&#x2F;bin:$PATH</span><br></pre></td></tr></table></figure><hr><h3 id="3-1-修改-Spark-配置文件"><a href="#3-1-修改-Spark-配置文件" class="headerlink" title="3.1 修改 Spark 配置文件"></a>3.1 修改 Spark 配置文件</h3><ul><li>配置 slaves 节点主机名 （注意：主节点主机名不要填写，只填写 slaves 节点的主机名。本文集群机器总共3台，一台主节点，两台 slaves 节点）</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@rhino001 ~]$ cd &#x2F;home&#x2F;rhino&#x2F;spark-2.2.0-bin-hadoop2.6&#x2F;conf </span><br><span class="line">[rhino@rhino001 conf]$ cp slaves.template slaves</span><br><span class="line">[rhino@rhino001 conf]$ vim slaves</span><br></pre></td></tr></table></figure><p>添加如下内容</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">node2</span><br><span class="line">node3</span><br></pre></td></tr></table></figure><ul><li>配置 <code>spark-en.sh</code> 文件</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@node1 ~]$ cd &#x2F;home&#x2F;rhino&#x2F;spark-2.2.0-bin-hadoop2.6&#x2F;conf</span><br><span class="line">[rhino@node1 conf]$ cp spark-env.sh.template spark-env.sh</span><br><span class="line">[rhino@node1 conf]$ vim spark-env.sh</span><br></pre></td></tr></table></figure><p>在spark-env.sh文件末添加所需的环境变量配置（实际路径根据实际情况填写）：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;&#x2F;home&#x2F;rhino&#x2F;jdk1.8.0_181</span><br><span class="line">export SCALA_HOME&#x3D;&#x2F;home&#x2F;rhino&#x2F;scala-2.11.7</span><br><span class="line">export SPARK_MASTER_IP&#x3D;192.168.50.213</span><br><span class="line">export SPARK_WORKER_MEMORY&#x3D;2g</span><br><span class="line">export HADOOP_CONF_DIR&#x3D;&#x2F;usr&#x2F;hdp&#x2F;2.6.3.0-235&#x2F;hadoop&#x2F;etc&#x2F;hadoop</span><br><span class="line">export YARN_CONF_DIR&#x3D;&#x2F;usr&#x2F;hdp&#x2F;2.6.3.0-235&#x2F;hadoop-yarn&#x2F;etc&#x2F;hadoop</span><br><span class="line">export SPARK_CONF_DIR&#x3D;&#x2F;home&#x2F;rhino&#x2F;spark-2.2.0-bin-hadoop2.6&#x2F;conf</span><br><span class="line">export SPARK_CLASSPATH&#x3D;$SPARK_CLASSPATH:&#x2F;home&#x2F;rhino&#x2F;spark-2.2.0-bin-hadoop2.6&#x2F;jars&#x2F;mysql-connector-java-5.1.35.jar</span><br></pre></td></tr></table></figure><ul><li><p>配置 <code>spark-defaults.conf</code> 文件，在 <code>spark-defaults.conf</code> 文件末添加所需的配置：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@node1 ~]$ cd &#x2F;home&#x2F;rhino&#x2F;spark-2.2.0-bin-hadoop2.6&#x2F;conf </span><br><span class="line">[rhino@node2 conf]$ cp spark-defaults.conf.template spark-defaults.conf </span><br><span class="line">[rhino@node3 conf]$ vim spark-defaults.conf</span><br></pre></td></tr></table></figure><p>添加如下内容（实际路径根据实际情况进行配置）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#spark临时目录</span><br><span class="line">spark.local.dir &#x2F;home&#x2F;rhino&#x2F;tmp</span><br><span class="line">spark.sql.warehouse.dir hdfs:&#x2F;&#x2F;mycluster&#x2F;user&#x2F;hive&#x2F;warehouse</span><br><span class="line">spark.yarn.jars hdfs:&#x2F;&#x2F;mycluster&#x2F;sharkjars-2.0&#x2F;*</span><br></pre></td></tr></table></figure></li><li><p>新建配置文件 <code>hive-site.xml</code></p></li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@node1 ]$ vim &#x2F;home&#x2F;rhino&#x2F;spark-2.2.0-bin-hadoop2.6&#x2F;conf&#x2F;hive-site.xml</span><br></pre></td></tr></table></figure><p>添加如下内容，注意根据实际情况，修改相关配置参数</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hive.metastore.client.socket.timeout&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;3600&lt;&#x2F;value&gt;</span><br><span class="line">&lt;description&gt;MetaStore Client socket timeout in seconds&lt;&#x2F;description&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionURL&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;jdbc:mysql:&#x2F;&#x2F;172.168.1.1:3306&#x2F;hive?createDatabaseIfNotExist&#x3D;true&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;com.mysql.jdbc.Driver&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionUserName&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;rhino&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionPassword&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;xxxxxxxx&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure><p>注意：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;javax.jdo.option.ConnectionURL&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;jdbc:mysql:&#x2F;&#x2F;172.168.1.1:3306&#x2F;hive?createDatabaseIfNotExist&#x3D;true&lt;&#x2F;value&gt;     # 这个value里面写的是hive存在mysql上的元数据库的地址，如果是使用ambari安装的hive，则ip应该为ambari使用的mysql的ip，后面的hive_rhino为hive生产环境的库名，如果不知道怎么配，直接登录ambari，点击Hive &gt; configs &gt; DATABASE，将Database URL 配置项的内容直接拷贝到&lt;value&gt; &lt;&#x2F;value&gt;之间即可</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">扩展：spark需要连接hive的元数据库，通过获取元数据库内的元数据，才能建立spark与hive的链接，从而能够使用sparksql来操作hive。</span><br></pre></td></tr></table></figure><hr><h3 id="3-2-拷贝-hadoop-的-jar-包【在-Spark-主节点的-root-用户下执行】"><a href="#3-2-拷贝-hadoop-的-jar-包【在-Spark-主节点的-root-用户下执行】" class="headerlink" title="3.2 拷贝 hadoop 的 jar 包【在 Spark 主节点的 root 用户下执行】"></a>3.2 拷贝 hadoop 的 jar 包【在 Spark 主节点的 root 用户下执行】</h3><p>从 <code>/usr/hdp/2.6.3.0-235/hadoop/client</code> 中拷贝 <code>jersey-client-1.9.jar</code> 和 <code>jersey-core-1.9.jar</code> 到 spark 的 jars 中</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">su - root</span><br><span class="line"></span><br><span class="line">[root@node1 ~]# cd &#x2F;usr&#x2F;hdp&#x2F;2.6.3.0-235&#x2F;hadoop&#x2F;client&#x2F;</span><br><span class="line">[root@node1 client] cp jersey-client-1.9.jar &#x2F;home&#x2F;rhino&#x2F;spark-2.2.0-bin-hadoop2.6&#x2F;jars</span><br><span class="line">[root@node1 client]# cp jersey-core-1.9.jar &#x2F;home&#x2F;rhino&#x2F;spark-2.2.0-bin-hadoop2.6&#x2F;jars</span><br><span class="line">[root@node1 client]# cd &#x2F;home&#x2F;rhino&#x2F;spark-2.2.0-bin-hadoop2.6&#x2F;jars</span><br><span class="line">[root@node1 jars]# chmod 755 *</span><br><span class="line">[root@node1 jars]# chown rhino:root *</span><br></pre></td></tr></table></figure><hr><h2 id="4、分发安装包至-slaves-节点【在-Spark-主节点的-rhino-用户下执行】"><a href="#4、分发安装包至-slaves-节点【在-Spark-主节点的-rhino-用户下执行】" class="headerlink" title="4、分发安装包至 slaves 节点【在 Spark 主节点的 rhino 用户下执行】"></a>4、分发安装包至 slaves 节点【在 Spark 主节点的 rhino 用户下执行】</h2><p>拷贝 <code>scala-2.11.7</code> 及环境变量到 slave 机器。（这里以安装3台为例）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@node1 ~]$ scp -r ~&#x2F;scala-2.11.7 rhino@node2:~</span><br><span class="line">[rhino@node1 ~]$ scp -r ~&#x2F;scala-2.11.7 rhino@node3:~</span><br></pre></td></tr></table></figure><p>拷贝 <code>spark-2.2.0-bin-hadoop2.6</code> 及环境变量到 slave 机器</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@node1 ~]$ scp -r ~&#x2F;spark-2.2.0-bin-hadoop2.6 rhino@node2:~</span><br><span class="line">[rhino@node1 ~]$ scp -r ~&#x2F;spark-2.2.0-bin-hadoop2.6 rhino@node3:~</span><br><span class="line">[rhino@node1 ~]$ scp ~&#x2F;.bashrc rhino@node2:~</span><br><span class="line">[rhino@node1 ~]$ scp ~&#x2F;.bashrc rhino@node3:~</span><br></pre></td></tr></table></figure><hr><h2 id="5、加载环境变量及创建软链接【在-Spark-所有节点的-rhino-用户下执行】"><a href="#5、加载环境变量及创建软链接【在-Spark-所有节点的-rhino-用户下执行】" class="headerlink" title="5、加载环境变量及创建软链接【在 Spark 所有节点的 rhino 用户下执行】"></a>5、加载环境变量及创建软链接【在 Spark 所有节点的 rhino 用户下执行】</h2><p>使每台机器环境变量生效</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@node1 ~]$ source ~&#x2F;.bashrc</span><br></pre></td></tr></table></figure><p>在每台机器上创建软链接</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@node1 ~]$ cd &#x2F;home&#x2F;rhino</span><br><span class="line">[rhino@node1 ~]$ ln -s spark-2.2.0-bin-hadoop2.6 spark</span><br></pre></td></tr></table></figure><hr><h2 id="6、上传-jar-包到-HDFS-【在-Spark-主节点的-rhino-用户下执行】"><a href="#6、上传-jar-包到-HDFS-【在-Spark-主节点的-rhino-用户下执行】" class="headerlink" title="6、上传 jar 包到 HDFS 【在 Spark 主节点的 rhino 用户下执行】"></a>6、上传 jar 包到 HDFS 【在 Spark 主节点的 rhino 用户下执行】</h2><p>将 spark 环境中的 jar 包上传到 HDFS</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@node1 ~]$hdfs dfs -mkdir hdfs:&#x2F;&#x2F;mycluster&#x2F;sharkjars-2.0&#x2F;</span><br><span class="line">[rhino@node1 ~]$ hdfs dfs -put ~&#x2F;spark-2.2.0-bin-hadoop2.6&#x2F;jars&#x2F;* hdfs:&#x2F;&#x2F;mycluster&#x2F;sharkjars-2.0&#x2F;</span><br></pre></td></tr></table></figure><p>验证 jar 包上传是否成功<br>通过浏览器登录 HDFS 界面：<code>http://172.168.1.1:50070/explorer.html</code><br>查看 Utilities 项，并选择 <code>browse the file system</code>，结果如下图：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image229.png" alt="image-229.png"></p><hr><h2 id="7、启动thriftserver【在-Spark-主节点的-rhino-用户下执行】"><a href="#7、启动thriftserver【在-Spark-主节点的-rhino-用户下执行】" class="headerlink" title="7、启动thriftserver【在 Spark 主节点的 rhino 用户下执行】"></a>7、启动thriftserver【在 Spark 主节点的 rhino 用户下执行】</h2><p>即启动 sparksql，需要时启动。</p><blockquote><p>如果不用 sparksql 就不要启动。</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">~&#x2F;spark&#x2F;sbin&#x2F;start-thriftserver.sh --master yarn-client --executor-memory 1g --executor-cores 2 --queue root.spark-mid</span><br></pre></td></tr></table></figure><blockquote><p>--executor-memory: 指定内存<br>--executor-cores: 指定核数<br>--queue: 指定 yarn 资源队列</p></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h2 id=&quot;1、Spark-简介&quot;&gt;&lt;a href=&quot;#1、Spark-简介&quot; class=&quot;headerlink&quot; title=&quot;1、Spark 简介&quot;&gt;&lt;/a&gt;1、Spark 简介&lt;/h2&gt;&lt;p&gt;Apache Spark 是一个分布式计算框架，旨在简化运行于计算机集群上的并行程序的编写。该框架对资源调度，任务的提交、执行和跟踪，节点间的通信以及数据并行处理的内在底层操作都进行了抽象。它提供了一个更高级别的 API 用于处理分布式数据。从这方面说，它与 Apache Hadoop 等分布式处理框架类似。但在底层架构上，Spark 与它们有所不同。&lt;/p&gt;
    
    </summary>
    
    
      <category term="CS Soft" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/"/>
    
      <category term="Server" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/"/>
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/Ambari/"/>
    
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/tags/Ambari/"/>
    
      <category term="Bigdata" scheme="https://winyter.github.io/MyBlog/tags/Bigdata/"/>
    
  </entry>
  
  <entry>
    <title>基于 Ambari 的大数据集群安装指导——篇十三：Ambari 安装 Impala</title>
    <link href="https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-13-install-impala-md/"/>
    <id>https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-13-install-impala-md/</id>
    <published>2020-05-31T09:53:13.000Z</published>
    <updated>2020-07-25T11:14:27.489Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="1、准备工作"><a href="#1、准备工作" class="headerlink" title="1、准备工作"></a>1、准备工作</h2><ul><li>确认 GreenPlum 版本，以及 GreenPlum 部署规划</li><li>确认 GreenPlum 的安装包是否已经上传到 Ambari Server 节点的 <code>/var/www/html/ambari/extend</code> 路径下</li><li>确认 GreenPlum 服务包是否已经上传到 Ambari Server 节点的 <code>/var/lib/ambari-server/resources/stacks/HDP/2.6/services</code> 路径下</li></ul><a id="more"></a><blockquote><p>如果版本包未上传，则需要上传到指定的目录，并且重启 ambari server</p></blockquote><hr><h2 id="2、安装部署Impala"><a href="#2、安装部署Impala" class="headerlink" title="2、安装部署Impala"></a>2、安装部署Impala</h2><ul><li>点击 <code>Add Service</code> 选择 Impala 服务并点击 <code>NEXT</code>：</li></ul><p><img src="http://cdn.winyter.cn/ambari-install-guide_image217.png" alt="image-217.png"></p><ul><li>添加 impala 的 <code>statestored/catalogd</code> 节点（需要放在同一台服务器上），点击 <code>NEXT</code></li></ul><blockquote><p>注意：statestored/catalogd 尽量不要安装在管理节点上。选择一台数据节点安装。且 statestored/catalogd 进程尽量不要和 impalad 合设。</p></blockquote><p><img src="http://cdn.winyter.cn/ambari-install-guide_image218.png" alt="image-218.png"></p><ul><li>选择 impalad 节点</li></ul><blockquote><p>impalad 进程和 datanode 保持一致。statestored/catalogd 进程所在的机器上不安装 impalad 进程。<br>这里机器较少，所以全部都选择了。</p></blockquote><p><img src="http://cdn.winyter.cn/ambari-install-guide_image219.png" alt="image-219.png"></p><ul><li><strong>Advanced hive-config content</strong> 中根据实际需求修改密码，并修改 URL 路径</li></ul><blockquote><p>根据实际情况修改 content 配置项中的 IP、端口、密码以及元数库名称。<br>如果 mysql 是双击切换，则这里填写的是虚拟 IP；元数据库为 hive_rhino；密码修改为 xxxxxxxx</p></blockquote><p><img src="http://cdn.winyter.cn/ambari-install-guide_image220.png" alt="image-220.png"></p><ul><li>在 <strong>Advanced impala-env</strong> 配置项中修改 <strong>impala_download</strong>、<strong>catalog_service_host</strong>、<strong>state_store_host</strong></li></ul><p>IP地址: <code>http://172.168.1.1/ambari/extend/impala-2.12.0.tar.gz</code><br>172.168.1.1 根据实际的 ambari server 地址填写。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image221.png" alt="image-221.png"></p><hr><h2 id="3、确认安装-Impala"><a href="#3、确认安装-Impala" class="headerlink" title="3、确认安装 Impala"></a>3、确认安装 Impala</h2><p>点击 <code>NEXT</code>，直到 <code>DEPOLY</code>，安装部署 impala<br><img src="http://cdn.winyter.cn/ambari-install-guide_image222.png" alt="image-222.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image223.png" alt="image-223.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image224.png" alt="image-224.png"></p><p>启动 catalog_service：<br>点击 <code>IMPALA_CATALOG_SERVICE</code> → <code>Start</code><br><img src="http://cdn.winyter.cn/ambari-install-guide_image225.png" alt="image-225.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image226.png" alt="image-226.png"></p><p>完成状态<br><img src="http://cdn.winyter.cn/ambari-install-guide_image227.png" alt="image-227.png"></p><hr><h2 id="4、启停"><a href="#4、启停" class="headerlink" title="4、启停"></a>4、启停</h2><p>点击右上角 <code>ACTIONS</code> 里的 <code>Stop</code>，即可执行停止服务操作；点击 <code>Start</code> ，即可执行启动服务操作。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image228.png" alt="image-228.png"></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h2 id=&quot;1、准备工作&quot;&gt;&lt;a href=&quot;#1、准备工作&quot; class=&quot;headerlink&quot; title=&quot;1、准备工作&quot;&gt;&lt;/a&gt;1、准备工作&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;确认 GreenPlum 版本，以及 GreenPlum 部署规划&lt;/li&gt;
&lt;li&gt;确认 GreenPlum 的安装包是否已经上传到 Ambari Server 节点的 &lt;code&gt;/var/www/html/ambari/extend&lt;/code&gt; 路径下&lt;/li&gt;
&lt;li&gt;确认 GreenPlum 服务包是否已经上传到 Ambari Server 节点的 &lt;code&gt;/var/lib/ambari-server/resources/stacks/HDP/2.6/services&lt;/code&gt; 路径下&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="CS Soft" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/"/>
    
      <category term="Server" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/"/>
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/Ambari/"/>
    
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/tags/Ambari/"/>
    
      <category term="Bigdata" scheme="https://winyter.github.io/MyBlog/tags/Bigdata/"/>
    
  </entry>
  
  <entry>
    <title>基于 Ambari 的大数据集群安装指导——篇十二：Ambari 安装 Neo4j</title>
    <link href="https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-12-install-neo4j-md/"/>
    <id>https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-12-install-neo4j-md/</id>
    <published>2020-05-31T09:52:10.000Z</published>
    <updated>2020-07-25T11:07:38.470Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="1、准备工作"><a href="#1、准备工作" class="headerlink" title="1、准备工作"></a>1、准备工作</h2><ul><li>确认 Neo4j 版本，以及 Neo4j 部署规划</li><li>确认 Neo4j 的安装包是否已经上传到 Ambari Server 节点的 <code>/var/www/html/ambari/extend</code> 路径下</li><li>确认 Neo4j 服务包是否已经上传到 Ambari Server 节点的 <code>/var/lib/ambari-server/resources/stacks/HDP/2.6/services</code> 路径下</li></ul><a id="more"></a><blockquote><p>如果版本包未上传，则需要上传到指定的目录，并且重启 ambari server</p></blockquote><hr><h2 id="2、安装部署Neo4j"><a href="#2、安装部署Neo4j" class="headerlink" title="2、安装部署Neo4j"></a>2、安装部署Neo4j</h2><p>点击 <code>Add Service</code> 选择 Neo4j 版本的服务并点击 <code>NEXT</code>：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image199.png" alt="image-199.png"></p><p>弹出如下图，点击 <code>NEXT</code> 按钮<br><img src="http://cdn.winyter.cn/ambari-install-guide_image200.png" alt="image-200.png"></p><p>修改 <strong>Advanced neo4j-env</strong> 中的 <strong>neo4j_download</strong> 配置<br><code>http://172.168.1.1/ambari/extend/neo4j.tar.gz</code>。（修改 IP 地址和 neo4j 包名）</p><blockquote><p>注意：端口号不能被占用。</p></blockquote><p><img src="http://cdn.winyter.cn/ambari-install-guide_image201.png" alt="image-201.png"></p><p>点击 <code>NEXT</code> 按钮，弹出如下图，点击红色按钮继续<br><img src="http://cdn.winyter.cn/ambari-install-guide_image202.png" alt="image-202.png"></p><hr><h2 id="3、确认安装"><a href="#3、确认安装" class="headerlink" title="3、确认安装"></a>3、确认安装</h2><p>点击 <code>DEPLOY</code> 按钮继续，等待安装完成。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image203.png" alt="image-203.png"></p><p>安装完成后页面如下图，点击 <code>NEXT</code><br><img src="http://cdn.winyter.cn/ambari-install-guide_image204.png" alt="image-204.png"></p><p>弹出如下图，点击 <code>COMPLETE</code> 按钮，完成结束。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image205.png" alt="image-205.png"></p><p>完成后页面如下图，左边红色框内服务前面的圆点是绿色，中间红色框内显示为已启动，右边红色框内显示的是 neo4j 服务自带的 web 快速连接，点击可跳转。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image206.png" alt="image-206.png"></p><hr><h2 id="4、启停"><a href="#4、启停" class="headerlink" title="4、启停"></a>4、启停</h2><hr><h3 id="4-1-启动"><a href="#4-1-启动" class="headerlink" title="4.1 启动"></a>4.1 启动</h3><p>neo4j 前置状态是已停止<br>登录 ambari 页面后，点击红色框内按钮进入 neo4j 主页面，如下图，点击右上角绿色的 <code>ACTIONS</code> 按钮<br><img src="http://cdn.winyter.cn/ambari-install-guide_image207.png" alt="image-207.png"></p><p>弹出如下图，点击红色框内按钮<br><img src="http://cdn.winyter.cn/ambari-install-guide_image208.png" alt="image-208.png"></p><p>弹出如下图，点击红色框内按钮，等待服务启动<br><img src="http://cdn.winyter.cn/ambari-install-guide_image209.png" alt="image-209.png"></p><p>弹出如下图，表示 neo4j 服务成功启动，点击绿色的 <code>OK</code> 按钮，结束<br><img src="http://cdn.winyter.cn/ambari-install-guide_image210.png" alt="image-210.png"></p><p>neo4j 服务启动后的主页面如下图<br><img src="http://cdn.winyter.cn/ambari-install-guide_image211.png" alt="image-211.png"></p><hr><h3 id="4-2-停止"><a href="#4-2-停止" class="headerlink" title="4.2 停止"></a>4.2 停止</h3><p>neo4j 前置状态是已启动<br>登录 ambari 页面后，点击红色框内按钮进入 neo4j 主页面，如下图，点击右上角绿色的 <code>ACTIONS</code> 按钮<br><img src="http://cdn.winyter.cn/ambari-install-guide_image212.png" alt="image-212.png"></p><p>弹出如下图，点击红色框内按钮<br><img src="http://cdn.winyter.cn/ambari-install-guide_image213.png" alt="imgae-213.png"></p><p>弹出如下图，点击红色框内按钮，等待服务停止<br><img src="http://cdn.winyter.cn/ambari-install-guide_image214.png" alt="image-214.png"></p><p>弹出如下图，表示 neo4j 服务成功停止，点击绿色的 <code>OK</code> 按钮，结束<br><img src="http://cdn.winyter.cn/ambari-install-guide_image215.png" alt="image-215.png"></p><p>neo4j服务停止后的主页面如下图<br><img src="http://cdn.winyter.cn/ambari-install-guide_image216.png" alt="image-216.png"></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h2 id=&quot;1、准备工作&quot;&gt;&lt;a href=&quot;#1、准备工作&quot; class=&quot;headerlink&quot; title=&quot;1、准备工作&quot;&gt;&lt;/a&gt;1、准备工作&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;确认 Neo4j 版本，以及 Neo4j 部署规划&lt;/li&gt;
&lt;li&gt;确认 Neo4j 的安装包是否已经上传到 Ambari Server 节点的 &lt;code&gt;/var/www/html/ambari/extend&lt;/code&gt; 路径下&lt;/li&gt;
&lt;li&gt;确认 Neo4j 服务包是否已经上传到 Ambari Server 节点的 &lt;code&gt;/var/lib/ambari-server/resources/stacks/HDP/2.6/services&lt;/code&gt; 路径下&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="CS Soft" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/"/>
    
      <category term="Server" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/"/>
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/Ambari/"/>
    
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/tags/Ambari/"/>
    
      <category term="Bigdata" scheme="https://winyter.github.io/MyBlog/tags/Bigdata/"/>
    
  </entry>
  
  <entry>
    <title>基于 Ambari 的大数据集群安装指导——篇十一：Ambari 安装 Kafka</title>
    <link href="https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-11-install-kafka-md/"/>
    <id>https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-11-install-kafka-md/</id>
    <published>2020-05-31T09:51:14.000Z</published>
    <updated>2020-07-25T11:07:24.651Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="1、准备工作"><a href="#1、准备工作" class="headerlink" title="1、准备工作"></a>1、准备工作</h2><ul><li>确认 Kafka 版本，以及 Kafka 部署规划</li><li>确认 Kafka 的安装包是否已经上传到 Ambari Server 节点的 <code>/var/www/html/ambari/extend</code> 路径下</li><li>确认 Kafka 服务包是否已经上传到 Ambari Server 节点的 <code>/var/lib/ambari-server/resources/stacks/HDP/2.6/services</code> 路径下</li></ul><a id="more"></a><blockquote><p>如果版本包未上传，则需要上传到指定的目录，并且重启 ambari server</p></blockquote><hr><h2 id="2、安装部署"><a href="#2、安装部署" class="headerlink" title="2、安装部署"></a>2、安装部署</h2><p>点击 <code>Add Service</code> 选择 Kafka1_1 服务并点击 <code>NEXT</code><br><img src="http://cdn.winyter.cn/ambari-install-guide_image185.png" alt="image-185.png"></p><p>添加 kafka1_1_broker 节点并点击 <code>NEXT</code></p><blockquote><p>Kafka部署情况以规划部署方案为准。这里以3台为例</p></blockquote><p><img src="http://cdn.winyter.cn/ambari-install-guide_image187.png" alt="image-186.png"></p><hr><h2 id="3、修改配置"><a href="#3、修改配置" class="headerlink" title="3、修改配置"></a>3、修改配置</h2><ul><li><strong>Advanced kafka1.1-broker-server</strong> 配置</li></ul><p><strong>port</strong>, 填写 <code>9092</code>，如果端口被占用，可根据实际情况进行修改；<br><strong>kafka.metrics.reporters</strong>，填写 <code>org.apache.hadoop.metrics2.sink.kafka.KafkaTimelineMetricsReporter</code> ;<br><strong>zookeeper.connect</strong>，配置所有 zookeeper 节点的 <code>主机名:端口</code>；<br><strong>log.dir</strong> 具体填写 <code>/data01/kafka-logs,/data02/kafka-logs,/data03/kafka-logs,/data04/kafka-logs,/data05/kafka-logs,/data06/kafka-logs,/data07/kafka-logs,/data08/kafka-logs,/data09/kafka-logs,/data010/kafka-logs</code> （如果有多块磁盘，并对kafka的性能有较高要求，建议在每个磁盘下都配置一个目录，这里以10块盘为例）</p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image187.png" alt="image-187.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image188.png" alt="image-188.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image189.png" alt="image-189.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image190.png" alt="image-190.png"></p><ul><li>kafka 老化时间配置</li></ul><p><strong>log.rentention.hours</strong>: 默认 168 小时，可根据实际流量计硬盘容量情况配置</p><blockquote><p>老化时间计算方法：<br>假设现网实际场景中，8 台 kafka 服务器，每台服务器 12 块盘，单块容量 1.8T；现网流量数据，最大吞吐值为 10Gbps。<br>那么 96X 1.8X 1024 X 1024 (M) ÷ （1.25 GB X 1024）÷ 3600(s) = 39.3 小时；即在峰值流量情况下，磁盘最多可保存 39.3 个小时的数据量。<br>为了保证磁盘利用率，10Gbps 流量情况下，老化时间配置为 8 小时；15Gbps 流量下配置为 6 小时。</p></blockquote><p><img src="http://cdn.winyter.cn/ambari-install-guide_image191.png" alt="image-191.png"></p><ul><li><strong>Advanced kafka1.1-env</strong> 配置</li></ul><p><strong>kafka_download</strong>，修改为：<code>http://172.168.1.1/ambari/extend/kafka-1.1.0.tar.gz</code><br><img src="http://cdn.winyter.cn/ambari-install-guide_image192.png" alt="image-192.png"></p><ul><li>Advanced kafka1.1-broker-server优化配置修改</li></ul><p><img src="http://cdn.winyter.cn/ambari-install-guide_image198.png" alt="image-198.png"></p><hr><h2 id="4、确认安装"><a href="#4、确认安装" class="headerlink" title="4、确认安装"></a>4、确认安装</h2><p>配置完成后一直点击下一步，执行安装部署：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image193.png" alt="image-193.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image194.png" alt="image-194.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image195.png" alt="image-195.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image196.png" alt="image-196.png"></p><hr><h2 id="5、手动修改部分参数【在所有-Kafka-Broker-节点的-kafka-用户下执行】"><a href="#5、手动修改部分参数【在所有-Kafka-Broker-节点的-kafka-用户下执行】" class="headerlink" title="5、手动修改部分参数【在所有 Kafka Broker 节点的 kafka 用户下执行】"></a>5、手动修改部分参数【在所有 Kafka Broker 节点的 kafka 用户下执行】</h2><blockquote><p>kafka 在安装完成后，部分配置内会存在一些使用 localhost 的参数，这可能会导致业务应用启动报错，建议按本节内容修改。<br>或者也可以跳过本节内容，届时如果业务应用启动时，报形如：Unexpected error fetching metadata for topic xxlww2 的错误时，再来修改这些参数。</p></blockquote><p>修改 <code>/home/kafka/kafka/kafka-1.1.0/conf</code> 下 <code>connect-distributed.properties</code>、<code>connect-standalone.properties</code>、<code>consumer.properties</code> 和 <code>producer.properties</code>，将四个配置文件内所有的 localhost 全部修改为实际的 IP 地址</p><hr><h2 id="6、启停"><a href="#6、启停" class="headerlink" title="6、启停"></a>6、启停</h2><p><img src="http://cdn.winyter.cn/ambari-install-guide_image197.png" alt="image-197.png"></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h2 id=&quot;1、准备工作&quot;&gt;&lt;a href=&quot;#1、准备工作&quot; class=&quot;headerlink&quot; title=&quot;1、准备工作&quot;&gt;&lt;/a&gt;1、准备工作&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;确认 Kafka 版本，以及 Kafka 部署规划&lt;/li&gt;
&lt;li&gt;确认 Kafka 的安装包是否已经上传到 Ambari Server 节点的 &lt;code&gt;/var/www/html/ambari/extend&lt;/code&gt; 路径下&lt;/li&gt;
&lt;li&gt;确认 Kafka 服务包是否已经上传到 Ambari Server 节点的 &lt;code&gt;/var/lib/ambari-server/resources/stacks/HDP/2.6/services&lt;/code&gt; 路径下&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="CS Soft" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/"/>
    
      <category term="Server" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/"/>
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/Ambari/"/>
    
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/tags/Ambari/"/>
    
      <category term="Bigdata" scheme="https://winyter.github.io/MyBlog/tags/Bigdata/"/>
    
  </entry>
  
  <entry>
    <title>基于 Ambari 的大数据集群安装指导——番外一：Greenplum 恢复操作</title>
    <link href="https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-ex1-recover-greenplum-md/"/>
    <id>https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-ex1-recover-greenplum-md/</id>
    <published>2020-05-31T09:49:46.000Z</published>
    <updated>2020-07-25T11:12:31.910Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>当 Greenplum 的组件异常时，可进行恢复操作。<br>Greenplum 恢复功能分为 2 大类：master 恢复和 primary(mirror) 恢复。</p></blockquote><hr><a id="more"></a><h2 id="1、master-恢复"><a href="#1、master-恢复" class="headerlink" title="1、master 恢复"></a>1、master 恢复</h2><p>当 master 主机出现故障时（monitor 依赖 master，如果 master 出故障，monitor 也出故障），如图：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image173.png" alt="image-173.png"></p><p>点击 <code>ACTIONS</code> 中的 <code>Activestandby</code> 按钮，通过 standby 恢复 master，执行成功后如下图：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image174.png" alt="image-174.png"></p><p>点击 <code>GPDB Master</code> 启动按钮，等待 master 状态恢复。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image175.png" alt="image-175.png"></p><p>点击 <code>GPDB Monitor</code> 启动按钮，等待 monitor 状态恢复。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image176.png" alt="image-176.png"></p><p>点击 <code>GPDB Standby Master</code> 启动按钮，等待 standby 状态恢复。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image177.png" alt="image-177.png"></p><hr><h2 id="2、Standby-Master-恢复"><a href="#2、Standby-Master-恢复" class="headerlink" title="2、Standby Master 恢复"></a>2、Standby Master 恢复</h2><p><img src="http://cdn.winyter.cn/ambari-install-guide_image178.png" alt="image-178.png"></p><p>当 standby 出现故障时，关闭 master，等状态全部 down 之后，点击 <code>ACTIONS</code> 中的 <code>start</code>。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image179.png" alt="image-179.png"></p><hr><h2 id="3、primary-mirror-恢复"><a href="#3、primary-mirror-恢复" class="headerlink" title="3、primary(mirror) 恢复"></a>3、primary(mirror) 恢复</h2><ul><li>recover</li></ul><p>当 host 出现状态 down 时，启动一下状态，如果还未恢复，使用 recover。<br>检查失败的 segment，&#39;d&#39; 代表 &#39;down&#39;</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@node1 ~]$ psql -c &quot;SELECT * FROM gp_segment_configuration WHERE status&#x3D;&#39;d&#39;;&quot;</span><br></pre></td></tr></table></figure><p><img src="http://cdn.winyter.cn/ambari-install-guide_image180.png" alt="image-180.png"></p><p>也可以通过 <code>gpstate -c</code> 查看</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rhino@hadoop134 ~]$ gpstate -c</span><br></pre></td></tr></table></figure><p><img src="http://cdn.winyter.cn/ambari-install-guide_image181.png" alt="image-181.png"></p><p>上图为 node2 机器上 <code>Mirror Failed(/data02/mirror/gpseg1)，(/data02/mirror/gpseg1)Primary Failed(/data02/gpdata/gpseg3)</code> 。因为都是一台机器上的 <code>/data02</code> 磁盘出了问题，怀疑是否是磁盘问题，如果没有挂载，需要挂载：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node2 ~]# mount &#x2F;dev&#x2F;sdc1 &#x2F;data02&#x2F;</span><br></pre></td></tr></table></figure><p>修复失败的 segment，点击 <code>ACTIONS</code> → <code>Recover</code></p><ul><li>fullrecover</li></ul><p>当 recover 失效或者 primary(mirror) 对应的磁盘出现文件缺失时，可以使用全量恢复.</p><ul><li>reblance</li></ul><p>当 primary segment 宕机，mirror 成为了 primary segment。执行 <code>gprecoverseg</code> 命令恢复失败 segment 后，当前 primary segment 是原来的 mirror，原来失败的 primary segment 变成了现在的 mirror。并没有恢复到系统初始化时候的角色状态，造成一个主机上有多个 primary segment，会导致系统处于非平衡状态，消耗更多的系统资源。 <code>gpstate -c</code> ，确认所有 mirrors 都是同步的。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image182.png" alt="image-182.png"></p><p>也可以通过 metrics 页面，查看 greenplum resyncing_mode 为 0 时，代表所有 mirrors 是同步的。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image183.png" alt="image-183.png"></p><p>如果 mirrors 的状态是 Resynchronizing，等待完成。当状态都为 &#39;Synchronized&#39;，就可以进行 reblance 操作。</p><blockquote><p>进行 reblance 切换的时候，建议不要做其他操作。reblance 成功后，greenplum unbalanced 为 0。</p></blockquote><p><img src="http://cdn.winyter.cn/ambari-install-guide_image184.png" alt="image-184.png"></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;当 Greenplum 的组件异常时，可进行恢复操作。&lt;br&gt;Greenplum 恢复功能分为 2 大类：master 恢复和 primary(mirror) 恢复。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
    
    </summary>
    
    
      <category term="CS Soft" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/"/>
    
      <category term="Server" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/"/>
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/Ambari/"/>
    
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/tags/Ambari/"/>
    
      <category term="Bigdata" scheme="https://winyter.github.io/MyBlog/tags/Bigdata/"/>
    
  </entry>
  
  <entry>
    <title>基于 Ambari 的大数据集群安装指导——篇十：Ambari 安装 GreenPlum</title>
    <link href="https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-10-install-greenplum-md/"/>
    <id>https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-10-install-greenplum-md/</id>
    <published>2020-05-31T09:47:55.000Z</published>
    <updated>2020-07-25T11:07:10.179Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="1、准备工作"><a href="#1、准备工作" class="headerlink" title="1、准备工作"></a>1、准备工作</h2><ul><li>确认 GreenPlum 版本，以及 GreenPlum 部署规划</li><li>确认 GreenPlum 的安装包是否已经上传到 Ambari Server 节点的 <code>/var/www/html/ambari/extend</code> 路径下</li><li>确认 GreenPlum 服务包是否已经上传到 Ambari Server 节点的 <code>/var/lib/ambari-server/resources/stacks/HDP/2.6/services</code> 路径下</li></ul><a id="more"></a><blockquote><p>如果版本包未上传，则需要上传到指定的目录，并且重启 ambari server</p></blockquote><hr><h3 id="1-1-修改-Linux-内核参数【在需要安装-GP-的节点的-root-用户下执行】"><a href="#1-1-修改-Linux-内核参数【在需要安装-GP-的节点的-root-用户下执行】" class="headerlink" title="1.1 修改 Linux 内核参数【在需要安装 GP 的节点的 root 用户下执行】"></a>1.1 修改 Linux 内核参数【在需要安装 GP 的节点的 root 用户下执行】</h3><blockquote><p>注意：本节有部分参数已经在安装 Ambari 前的准备工作中做完，所以请先检查参数是否已经修改，没有修改的再进行修改</p></blockquote><ul><li>修改 <code>sysctl.conf</code> 文件</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]# su - root</span><br><span class="line">[root@node1 ~]# vim &#x2F;etc&#x2F;sysctl.conf</span><br></pre></td></tr></table></figure><p>添加如下内容：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vm.max_map_count &#x3D; 262144</span><br><span class="line">vm.swappiness &#x3D; 0</span><br><span class="line">vm.min_free_kbytes &#x3D; 2097152</span><br><span class="line">vm.extra_free_kbytes &#x3D; 4194304</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fs.aio-max-nr &#x3D; 1048576</span><br><span class="line">fs.file-max &#x3D; 76724600</span><br><span class="line"></span><br><span class="line">kernel.sem &#x3D; 250 5120000 100 20480</span><br><span class="line"></span><br><span class="line"># 所有共享内存段加起来最大(例如，主机内存256G，则使用内存的80%，单位PAGE&#x3D;4096)</span><br><span class="line"># 计算方法为：256*0.8*1024*1024*1024&#x2F;4096</span><br><span class="line">kernel.shmall &#x3D; 53687092</span><br><span class="line"># 单个共享内存段最大(主机内存的一半，单位字节)</span><br><span class="line"># 计算方法为：256&#x2F;2*1024*1024*1024</span><br><span class="line">kernel.shmmax &#x3D; 137438953472</span><br><span class="line">kernel.shmmni &#x3D; 4096</span><br><span class="line">kernel.sysrq &#x3D; 1</span><br><span class="line">kernel.core_users_pid &#x3D; 1</span><br><span class="line">kernel.msgmnb &#x3D; 65536</span><br><span class="line">kernel.msgmax &#x3D; 65536</span><br><span class="line">kernel.msgmni &#x3D; 2048</span><br><span class="line"></span><br><span class="line">net.core.netdev_max_backlog &#x3D; 10000</span><br><span class="line">net.core.rmem_max &#x3D; 4194304</span><br><span class="line">net.core.wmem_max &#x3D; 4194304</span><br><span class="line">net.core.rmem_default &#x3D; 262144</span><br><span class="line">net.core.wmem_default &#x3D; 262144</span><br><span class="line">net.core.somaxconn &#x3D; 4096</span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_max_syn_backlog &#x3D; 4096</span><br><span class="line">net.ipv4.tcp_keepalive_intvl &#x3D; 20</span><br><span class="line">net.ipv4.tcp_keepalive_probes &#x3D; 3</span><br><span class="line">net.ipv4.tcp_keepalive_time &#x3D; 60</span><br><span class="line">net.ipv4.tcp_mem &#x3D; 8388608 12582912 16777216</span><br><span class="line">net.ipv4.tcp_fin_timeout &#x3D; 5</span><br><span class="line">net.ipv4.tcp_synack_retries &#x3D; 2</span><br><span class="line">net.ipv4.tcp_syncookies &#x3D; 1</span><br><span class="line">net.ipv4.tcp_timestamps &#x3D; 1</span><br><span class="line">net.ipv4.tcp_rmem &#x3D; 8192 87380 16777216</span><br><span class="line">net.ipv4.tcp_wmem &#x3D; 8192 65536 16777216</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># net.ipv4.tcp_tw_recycle和net.ipv4.tcp_timestamps不建议同时开启</span><br><span class="line">net.ipv4.tcp_tw_recycle &#x3D; 1</span><br><span class="line">net.ipv4.tcp_tw_reuse &#x3D; 1</span><br><span class="line">net.ipv4.tcp_max_tw_buckets &#x3D; 200000</span><br><span class="line">net.ipv4.ip_local_port_range &#x3D; 10000 65535</span><br><span class="line">net.ipv4.ip_forward &#x3D; 0</span><br><span class="line">net.ipv4.conf.default.accept_source_route &#x3D; 0</span><br><span class="line">net.ipv4.conf.default.rp_filter &#x3D; 1</span><br><span class="line">net.ipv4.conf.default.arp_filter &#x3D; 1</span><br><span class="line">net.ipv4.conf.all.arp_filter &#x3D; 1</span><br><span class="line"></span><br><span class="line"># CentOS 6</span><br><span class="line"># net.nf_conntrack_max &#x3D; 1000000</span><br><span class="line"># net.netfilter.nf_conntrack_max &#x3D; 1000000</span><br><span class="line"></span><br><span class="line"># 根据实际IOPS能力以及内存大小设置</span><br><span class="line">vm.dirty_background_bytes &#x3D; 4096000000</span><br><span class="line">vm.dirty_expire_centisecs &#x3D; 6000</span><br><span class="line">vm.dirty_ratio &#x3D; 80</span><br><span class="line">vm.dirty_writeback_centisecs &#x3D; 50</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 6xxxx 防止内核隐藏的BUG导致的问题</span><br><span class="line"># vm.mmap_min_addr &#x3D;</span><br><span class="line"></span><br><span class="line"># vm.overcommit_memory &#x3D;0时，vm.overcommit_ratio可以不设置</span><br><span class="line">vm.overcommit_memory &#x3D; 2</span><br><span class="line">vm.overcommit_ratio &#x3D; 95</span><br><span class="line"></span><br><span class="line"># 不使用NUMA</span><br><span class="line">vm.zone_reclaim_mode &#x3D; 0</span><br><span class="line"># 如果要使用PostgreSQL的huge page，建议设置它。大于数据库需要的共享内存即可。</span><br><span class="line"># vm.nr_hugepages &#x3D; 102352</span><br></pre></td></tr></table></figure><blockquote><p>注意：vm.overcommit_ratio=95，是通过网页地址<a href="http://greenplum.org/calc/" target="_blank" rel="noopener">http://greenplum.org/calc/</a>, 输入服务器总内存，得出的结果之一。</p></blockquote><p>执行 <code>sysctl -p</code> 使其配置生效。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]# sysctl -p</span><br></pre></td></tr></table></figure><ul><li>关闭监控程序的服务端和客户端</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]# systemctl start tuned</span><br><span class="line">[root@node1 ~]# tuned-adm off</span><br><span class="line">[root@node1 ~]# tuned-adm list</span><br><span class="line">[root@node1 ~]# systemctl stop tuned</span><br><span class="line">[root@node1 ~]# systemctl disable tuned</span><br></pre></td></tr></table></figure><ul><li>修改 <code>limits.conf</code></li></ul><blockquote><p>该文件中的参数，部分与此前修改的有重复，以之前修改的为准</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@rhino131 ~]# vim &#x2F;etc&#x2F;security&#x2F;limits.conf</span><br></pre></td></tr></table></figure><p>修改如下内容</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 65536</span><br><span class="line">* soft nproc 131072</span><br><span class="line">* hard nproc 131072</span><br><span class="line">* soft core unlimited</span><br><span class="line">* - memlock unlimited</span><br><span class="line">* - as      unlimited</span><br><span class="line">* - data    unlimited</span><br><span class="line">* - fsize   unlimited</span><br><span class="line">* - rss     unlimited</span><br><span class="line">* - nproc unlimited</span><br></pre></td></tr></table></figure><ul><li>删除 <code>nproc</code> 限制</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]# rm -rf &#x2F;etc&#x2F;security&#x2F;limits.d&#x2F;*</span><br></pre></td></tr></table></figure><hr><h3 id="1-2-配置daedb用户无密码访问"><a href="#1-2-配置daedb用户无密码访问" class="headerlink" title="1.2 配置daedb用户无密码访问"></a>1.2 配置daedb用户无密码访问</h3><p>在创建gp集群时（集群数大于等于2），需要手动建立信任关系。</p><hr><h4 id="1-2-1-创建-daedb-用户【在所有-GP-节点的-root-用户下执行】"><a href="#1-2-1-创建-daedb-用户【在所有-GP-节点的-root-用户下执行】" class="headerlink" title="1.2.1 创建 daedb 用户【在所有 GP 节点的 root 用户下执行】"></a>1.2.1 创建 daedb 用户【在所有 GP 节点的 root 用户下执行】</h4><p>密码根据需求设置</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]# useradd -m daedb</span><br><span class="line">[root@node1 ~]# passwd daedb</span><br></pre></td></tr></table></figure><hr><h4 id="1-2-2-设置-daedb-用户的无密码访问【在所有-GP-节点的-root-用户下执行】"><a href="#1-2-2-设置-daedb-用户的无密码访问【在所有-GP-节点的-root-用户下执行】" class="headerlink" title="1.2.2 设置 daedb 用户的无密码访问【在所有 GP 节点的 root 用户下执行】"></a>1.2.2 设置 daedb 用户的无密码访问【在所有 GP 节点的 root 用户下执行】</h4><p>本节所有操作都需要顺序在每个 GP 节点上操作一遍</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]# su - daedb</span><br><span class="line">[root@node1 ~]# ssh-keygen -t rsa</span><br></pre></td></tr></table></figure><p><img src="http://cdn.winyter.cn/ambari-install-guide_image156.png" alt="image-156.png"></p><p>将公钥复制到需要无密码登陆的服务器上</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[daedb@node1 ~]# ssh-copy-id -i ~&#x2F;.ssh&#x2F;id_rsa.pub daedb@172.168.1.1</span><br><span class="line">[daedb@node1 ~]# ssh-copy-id -i ~&#x2F;.ssh&#x2F;id_rsa.pub daedb@172.168.1.2</span><br><span class="line">[daedb@node1 ~]# ssh-copy-id -i ~&#x2F;.ssh&#x2F;id_rsa.pub daedb@172.168.1.3</span><br></pre></td></tr></table></figure><blockquote><p>请严格操作，否则后续会报错。机器首次安装需要做，后面重复安装可不需要进行此命令。</p></blockquote><p>验证无密码访问是否成功。</p><p>集群内的机器都做好无密码访问后，通过ssh指令来验证，看集群内的机器是否都已经达到了互相之间的无密码访问。首次必须要操作。<br>例如在 node1 节点上可以分别执行：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[daedb@node1 ~]# ssh daedb@172.168.1.1</span><br><span class="line">[daedb@node1 ~]# ssh daedb@172.168.1.2</span><br><span class="line">[daedb@node1 ~]# ssh daedb@172.168.1.3</span><br></pre></td></tr></table></figure><hr><h3 id="1-3-Swap分区配置【在所有-GP-节点的-root-用户下执行】"><a href="#1-3-Swap分区配置【在所有-GP-节点的-root-用户下执行】" class="headerlink" title="1.3 Swap分区配置【在所有 GP 节点的 root 用户下执行】"></a>1.3 Swap分区配置【在所有 GP 节点的 root 用户下执行】</h3><blockquote><p>如果swap分区大小已经是64G，本节内容可以忽略不操作。</p></blockquote><p>配置建议：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image157.png" alt="image-157.png"></p><p>生成交换分区文件，注意交换分区的大小需要根据实际的内存大小而定，物理内存 256G 为例，生成 SWAP 为 64G 左右。执行以下命令进行修改。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]# dd bs&#x3D;1024k if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;&#x2F;home&#x2F;swap conv&#x3D;fdatasync count&#x3D;65526</span><br><span class="line">[root@node1 ~]# &#x2F;sbin&#x2F;mkswap &#x2F;home&#x2F;swap</span><br><span class="line">[root@node1 ~]# &#x2F;sbin&#x2F;swapon &#x2F;home&#x2F;swap</span><br></pre></td></tr></table></figure><p>查看是否swap生效</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]# free -g</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">              total        used        free      shared     buff&#x2F;cache     available</span><br><span class="line">Mem:          376           126          71         4           178           235</span><br><span class="line">Swap:          79            0           79</span><br></pre></td></tr></table></figure><hr><h3 id="1-4-本地-YUM-源安装-gp-需要的软件"><a href="#1-4-本地-YUM-源安装-gp-需要的软件" class="headerlink" title="1.4 本地 YUM 源安装 gp 需要的软件"></a>1.4 本地 YUM 源安装 gp 需要的软件</h3><p>执行以下命令，出现报错可忽略。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install rsync</span><br><span class="line">yum -y install coreutils</span><br><span class="line">yum -y install glib2</span><br><span class="line">yum -y install lrzsz</span><br><span class="line">yum -y install sysstat</span><br><span class="line">yum -y install e4fsprogs</span><br><span class="line">yum -y install xfsprogs</span><br><span class="line">yum -y install ntp</span><br><span class="line">yum -y install zlib</span><br><span class="line">yum -y install openssl</span><br><span class="line">yum -y install smartmontools</span><br><span class="line">yum -y install flex</span><br><span class="line">yum -y install bison</span><br><span class="line">yum -y install perl</span><br><span class="line">yum -y install perl-ExtUtils*</span><br><span class="line">yum -y install OpenIPMI-tools</span><br><span class="line">yum -y install openldap</span><br><span class="line">yum -y install logrotate</span><br><span class="line">yum -y install python-py</span><br><span class="line">yum -y installed</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#nfs功能使用</span><br><span class="line">yum -y install nfs-utils</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#虚拟IP设置使用，需要进入mnt挂载目录Package下执行</span><br><span class="line">yum -y install keepalived</span><br></pre></td></tr></table></figure><hr><h2 id="2、安装部署-GreenPlum"><a href="#2、安装部署-GreenPlum" class="headerlink" title="2、安装部署 GreenPlum"></a>2、安装部署 GreenPlum</h2><p>进入ambari界面后点击 <code>…</code> 选择 <code>Add Service</code>，在选项框中勾选上 GreenPlum，点击 <code>NEXT</code>。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image158.png" alt="image-158.png"></p><p>选择需要安装的服务器，GPDB Monitor需要与GPDB Master安装在同一台服务器上，GPDB Standby Master与GPDB Master不可选同一台机器。继续点击下一步。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image159.png" alt="image-159.png"></p><p>选择需要安装的GPDB Host。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image160.png" alt="image-160.png"></p><hr><h3 id="2-1-修改-GreenPlum-配置文件"><a href="#2-1-修改-GreenPlum-配置文件" class="headerlink" title="2.1 修改 GreenPlum 配置文件"></a>2.1 修改 GreenPlum 配置文件</h3><ul><li>【Advanced gp-env】配置项：</li></ul><p>&lt;1&gt; <strong>metrics_collector_host_ip</strong>： 填写 Ambari Metrics 的地址<br>&lt;2&gt; <strong>gp_base_dir</strong>： gp安装目录<br>&lt;3&gt; <strong>gp_log_dir</strong>： gp日志存放目录<br>&lt;4&gt; <strong>gp_pid_dir</strong>： pid存放目录<br>&lt;5&gt; <strong>gp_download</strong>： gp版本存放目录，修改IP和需要安装的包名称<br>&lt;6&gt; <strong>gp_conf_dir</strong> : gp配置文件目录（暂时不用）<br>&lt;7&gt; <strong>greenplum_monitor_download_url</strong>： greenplum monitor 监控版本存放目录，需修改默认值中的 ip<br>&lt;8&gt; <strong>host_disk_num</strong>： greenplum 使用的磁盘数，存放 gp 数据，根据实际磁盘数量填写。（单台机器上的数目）<br>&lt;9&gt; <strong>seg_hosts</strong>: 配置部署集群的服务器 host，如 node1,node2,node3<br>中间用英文逗号隔开<br>&lt;10&gt; <strong>standby_hostname</strong>： greenplum standby master 节点的主机名</p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image161.png" alt="image-161"></p><ul><li>【Advanced gp-mirror】配置项:</li></ul><p>&lt;1&gt; <strong>mirror_host_num</strong>： 集群中 mirror 机器数量<br>&lt;2&gt; <strong>mirror_host_seq</strong>： 安装 mirror 与机器之间的对应，顺序要颠倒</p><blockquote><p>mirror_host_seq配置说明<br>如果gp安装3台机器，seg_hosts填写的是 node1,node2,node3，那么 mirror_host_seq 就需要反过来写 node3,node2,node1</p></blockquote><p><img src="http://cdn.winyter.cn/ambari-install-guide_image162.png" alt="image-162.png"></p><ul><li>【Advanced greenplum-site】配置项：</li></ul><p>&lt;1&gt; <strong>greenplum_data_dir</strong>: Primary segment 数据目录， 如 <code>/data01/gpdata /data02/gpdata</code> 中间使用空格分开，根据实际需要填写。<br>&lt;2&gt; <strong>mirror_data_directory</strong>: Mirror segment 数据目录，如 <code>/data01/mirror /data02/mirror</code> 中间用空格分开，根据实际需要填写。<br>&lt;3&gt; <strong>master_directory</strong>: 指定 master 数据目录<br>&lt;4&gt; <strong>machine_list_file</strong>: seghosts 文件目录</p><p>其他采用默认值即可，如下图所示：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image163.png" alt="image-163.png"></p><hr><h3 id="2-2-确认安装GreenPlum"><a href="#2-2-确认安装GreenPlum" class="headerlink" title="2.2 确认安装GreenPlum"></a>2.2 确认安装GreenPlum</h3><p>点击 <code>PROCEED ANYWAY</code> ,点击 <code>DEPLOY</code> 继续下一步，然后查看版本安装进度。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image164.png" alt="image-164.png"></p><hr><h3 id="2-3-完成安装-GreenPlum"><a href="#2-3-完成安装-GreenPlum" class="headerlink" title="2.3 完成安装 GreenPlum"></a>2.3 完成安装 GreenPlum</h3><p>安装启动正常后，可以看到 GPDB Master 和 GPDB Host 的绿色标记。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image165.png" alt="image-165.png"></p><p>GreenPlum 安装启动正常后，可在服务器 daedb 用户下输入 gpstate 命令进行查看，如下图所示，能查看到 gp 的信息，说明 gp 已经正常启动了。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image166.png" alt="image-166.png"></p><blockquote><p>gp 初次安装完成后，建议重启一次，因为有可能起不来，原因是需要给 gpmaster 目录和子目录 700 权限，gp 在服务器重启后，需要检查 swap 挂载以及 daedb 用户下的 gpmaster 目录和子目录的权限，需要给 700 权限</p></blockquote><hr><h2 id="3、启停GreenPlum"><a href="#3、启停GreenPlum" class="headerlink" title="3、启停GreenPlum"></a>3、启停GreenPlum</h2><p>如果要停掉 gp 服务，Services 目录下选中 <code>GREENPLUM</code>，点击 <code>ACTIONS</code> 选择 <code>stop</code> 即可将 gp 数据库停掉。此时在服务器输入 gpstate 查看，如下图所示：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image167.png" alt="image-167.png"></p><hr><h2 id="4、安装失败后重装操作"><a href="#4、安装失败后重装操作" class="headerlink" title="4、安装失败后重装操作"></a>4、安装失败后重装操作</h2><p>如果在 ambari 上安装 greenplum 失败后需要重装，则需要在服务器创建的 daedb 用户下执行以下命令进行重置。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">每个节点都需要操作</span><br><span class="line">[root@node1 ~]# su - daedb</span><br><span class="line">[daedb@node1 ~]$ gpstop -a -M immediate</span><br><span class="line">[daedb@node1 ~]$ cd &#x2F;home&#x2F;daedb&#x2F;daedb&#x2F;etc</span><br><span class="line">[daedb@node1 ~]$ gpssh -f seghosts</span><br><span class="line"></span><br><span class="line">rm -fr &#x2F;tmp&#x2F;.s.PGSQL.*</span><br><span class="line">rm -fr &#x2F;home&#x2F;daedb&#x2F;*</span><br><span class="line">rm -fr &#x2F;data*&#x2F;gpdata&#x2F;*</span><br><span class="line">rm -fr &#x2F;data*&#x2F;mirror&#x2F;*</span><br><span class="line">最后还需要删除 &#x2F;var&#x2F;run 下所有 daedb 属组的文件及目录</span><br></pre></td></tr></table></figure><hr><h2 id="5、Greenplum告警配置"><a href="#5、Greenplum告警配置" class="headerlink" title="5、Greenplum告警配置"></a>5、Greenplum告警配置</h2><p>若需要对 Greenplum 进行监控，则进行以下操作。</p><p>点击页面 metrics 标签下的 <code>+</code> 号：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image168.png" alt="image-168.png"></p><p>点击 <code>Create Widget</code><br><img src="http://cdn.winyter.cn/ambari-install-guide_image169.png" alt="image-169.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image170.png" alt="image-170.png"></p><p>按如图进行配置：<br>依次选中以下参数，点击 <code>ADD</code> 即可。若要增加多个参数，点击 <code>Add Expression</code>。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image171.png" alt="image-171.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image172.png" alt="image-172.png"></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h2 id=&quot;1、准备工作&quot;&gt;&lt;a href=&quot;#1、准备工作&quot; class=&quot;headerlink&quot; title=&quot;1、准备工作&quot;&gt;&lt;/a&gt;1、准备工作&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;确认 GreenPlum 版本，以及 GreenPlum 部署规划&lt;/li&gt;
&lt;li&gt;确认 GreenPlum 的安装包是否已经上传到 Ambari Server 节点的 &lt;code&gt;/var/www/html/ambari/extend&lt;/code&gt; 路径下&lt;/li&gt;
&lt;li&gt;确认 GreenPlum 服务包是否已经上传到 Ambari Server 节点的 &lt;code&gt;/var/lib/ambari-server/resources/stacks/HDP/2.6/services&lt;/code&gt; 路径下&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="CS Soft" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/"/>
    
      <category term="Server" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/"/>
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/Ambari/"/>
    
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/tags/Ambari/"/>
    
      <category term="Bigdata" scheme="https://winyter.github.io/MyBlog/tags/Bigdata/"/>
    
  </entry>
  
  <entry>
    <title>基于 Ambari 的大数据集群安装指导——篇九：Ambari 安装 Redis</title>
    <link href="https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-9-install-redis-md/"/>
    <id>https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-9-install-redis-md/</id>
    <published>2020-05-31T09:46:56.000Z</published>
    <updated>2020-07-25T11:14:05.803Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="1、准备工作"><a href="#1、准备工作" class="headerlink" title="1、准备工作"></a>1、准备工作</h2><ul><li>确认 Redis 版本，以及 Redis 部署规划</li><li>确认 Redis 的安装包是否已经上传到 Ambari Server 节点的 <code>/var/www/html/ambari/extend</code> 路径下</li><li>确认 Redis 服务包是否已经上传到 Ambari Server 节点的 <code>/var/lib/ambari-server/resources/stacks/HDP/2.6/services</code> 路径下</li></ul><a id="more"></a><blockquote><p>如果版本包未上传，则需要上传到指定的目录，并且重启 ambari server</p></blockquote><hr><h2 id="2、安装部署-Redis"><a href="#2、安装部署-Redis" class="headerlink" title="2、安装部署 Redis"></a>2、安装部署 Redis</h2><p>点击 <code>Add Service</code> 选择 Redis 服务并点击 <code>NEXT</code><br><img src="http://cdn.winyter.cn/ambari-install-guide_image141.png" alt="image-141.png"></p><p>根据部署规划，添加 redis master 节点和 redis monitor 节点并点击 <code>NEXT</code><br><img src="http://cdn.winyter.cn/ambari-install-guide_image142.png" alt="image-142.png"></p><p>根据部署规划，添加redis slave节点<br><img src="http://cdn.winyter.cn/ambari-install-guide_image143.png" alt="image-143.png"></p><hr><h2 id="3、修改-Redis-配置文件"><a href="#3、修改-Redis-配置文件" class="headerlink" title="3、修改 Redis 配置文件"></a>3、修改 Redis 配置文件</h2><ul><li>在 <strong>Advand redis-conf-cluster</strong> 配置项</li></ul><p>勾选 <code>Cluster Enabled</code> 选项<br><strong>Cluster Master Host List</strong>: 添加之前选择节点的 ip 地址<br><strong>Cluster Slave Host List</strong>:  添加之前选择节点的 ip 地址<br>具体如下所示：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image144.png" alt="image-144.png"></p><ul><li>在 <strong>Advanced redis-conf-storage</strong> 配置项中，可修改 <strong>DB Directory</strong> 选项的数据存储路径</li></ul><blockquote><p>数据存放路径最好选择在已经做了 RAID ，且非 RAID0 的磁盘阵列上，这样数据有备份保障，如果不能满足，建议选择一块数据盘存放，比如：/data01/redis/data1</p></blockquote><p><img src="http://cdn.winyter.cn/ambari-install-guide_image145.png" alt="image-145.png"></p><ul><li>在 <strong>Advanced redis-env</strong> 配置项中</li></ul><p>修改 <strong>Metrics Collector Host Ip</strong>，对应 metric collector 进程所在的服务器地址；<br>修改 <strong>Redis Download Url</strong> 配置里 IP 地址：<code>http://72.168.1.1/ambari/extend/redis-5.0.3.tar.gz</code>（<code>redis-5.0.3.tar.gz</code> 这个包名称根据实际的redis的版本名称进行修改）IP 为 ambari severIP<br>修改 <strong>Redis Monitor Download Url</strong> 配置里的 IP 地址：<code>http://172.168.1.1/ambari/extend/redis-monitor.tar.gz</code>，对应 http 服务所在的 ip 地址（http 安装在 ambari sever 上的）<br>修改 <strong>Redis Monitor Config</strong>，修改为 <code>/home/redis/redis.properties</code>。稍后安装完成后，再修改这个文件的内容</p><p>具体如下：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image146.png" alt="image-146.png"></p><hr><h2 id="4、确认安装"><a href="#4、确认安装" class="headerlink" title="4、确认安装"></a>4、确认安装</h2><p>配置完成后一直点击下一步，执行安装部署<br><img src="http://cdn.winyter.cn/ambari-install-guide_image148.png" alt="image-148.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image149.png" alt="image-149.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image150.png" alt="image-150.png"></p><hr><h2 id="5、完成安装"><a href="#5、完成安装" class="headerlink" title="5、完成安装"></a>5、完成安装</h2><p><img src="http://cdn.winyter.cn/ambari-install-guide_image151.png" alt="image-151.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image152.png" alt="image-152.png"></p><p>安装完成后，redis服务进程展示<br><img src="http://cdn.winyter.cn/ambari-install-guide_image153.png" alt="image-153.png"></p><hr><h2 id="6、修改-Redis-Monitor-配置【在-Redis-Monitor-所在节点的-Redis-用户下执行】"><a href="#6、修改-Redis-Monitor-配置【在-Redis-Monitor-所在节点的-Redis-用户下执行】" class="headerlink" title="6、修改 Redis Monitor 配置【在 Redis Monitor 所在节点的 Redis 用户下执行】"></a>6、修改 Redis Monitor 配置【在 Redis Monitor 所在节点的 Redis 用户下执行】</h2><p>由上图可以发现，Redis Monitor 没有启动成功，这是由于在配置时，我们制定了一个文件：<code>/home/redis/redis.properties</code>，这个文件，乃至redis这个用户，在安装redis之前，都不存在，因此在安装时，Redis Monitor 读取不到这个文件，于是就在它的目录下新建了一个默认文件，此时，我们需要修改该文件，然后，拷贝到配置指定的目录下。<br>首先修改文件：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;home&#x2F;redis&#x2F;redis&#x2F;monitor</span><br><span class="line">vim redis.properties</span><br></pre></td></tr></table></figure><p>文件内容如下，按照以下说明，修改每个配置：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># redis master 节点列表，逗号分隔</span><br><span class="line">masterIpList&#x3D;172.168.1.1,172.168.1.2,172.168.1.3</span><br><span class="line"># redis master 端口号，如果没有修改，一般默认为 6379</span><br><span class="line">masterPort&#x3D;6379</span><br><span class="line"># redis slave 节点列表，逗号分隔</span><br><span class="line">slaveIpList&#x3D;172.168.1.1,172.168.1.2,172.168.1.3</span><br><span class="line"># redis slave 端口号，如果没有修改，一般默认为 6380</span><br><span class="line">slavePort&#x3D;6380</span><br><span class="line"># Ambari Metrics 节点 IP</span><br><span class="line">metric_host&#x3D;172.168.1.1</span><br><span class="line"># Redis 密码，如果没有特别配置，一般默认为空</span><br><span class="line">password&#x3D;</span><br></pre></td></tr></table></figure><p>修改完成后，复制该文件到指定目录：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp &#x2F;home&#x2F;redis&#x2F;monitor&#x2F;redis.properties &#x2F;home&#x2F;redis</span><br></pre></td></tr></table></figure><p>然后，回到 Ambari 界面，单独启动 Redis Monitor 即可</p><hr><h2 id="7、启停"><a href="#7、启停" class="headerlink" title="7、启停"></a>7、启停</h2><p>点击右上角ACTIONS里的Stop，即可执行停止服务操作<br><img src="http://cdn.winyter.cn/ambari-install-guide_image154.png" alt="image-154.png"></p><p>点击右上角ACTIONS里的Start，启动停止后的服务<br><img src="http://cdn.winyter.cn/ambari-install-guide_image155.png" alt="image-155.png"></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h2 id=&quot;1、准备工作&quot;&gt;&lt;a href=&quot;#1、准备工作&quot; class=&quot;headerlink&quot; title=&quot;1、准备工作&quot;&gt;&lt;/a&gt;1、准备工作&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;确认 Redis 版本，以及 Redis 部署规划&lt;/li&gt;
&lt;li&gt;确认 Redis 的安装包是否已经上传到 Ambari Server 节点的 &lt;code&gt;/var/www/html/ambari/extend&lt;/code&gt; 路径下&lt;/li&gt;
&lt;li&gt;确认 Redis 服务包是否已经上传到 Ambari Server 节点的 &lt;code&gt;/var/lib/ambari-server/resources/stacks/HDP/2.6/services&lt;/code&gt; 路径下&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="CS Soft" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/"/>
    
      <category term="Server" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/"/>
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/Ambari/"/>
    
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/tags/Ambari/"/>
    
      <category term="Bigdata" scheme="https://winyter.github.io/MyBlog/tags/Bigdata/"/>
    
  </entry>
  
  <entry>
    <title>基于 Ambari 的大数据集群安装指导——篇八：Ambari 安装 Hive</title>
    <link href="https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-8-install-hive-md/"/>
    <id>https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-8-install-hive-md/</id>
    <published>2020-05-31T09:44:35.000Z</published>
    <updated>2020-07-25T11:14:09.041Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="1、准备工作"><a href="#1、准备工作" class="headerlink" title="1、准备工作"></a>1、准备工作</h2><ul><li>确认 Hive 版本，以及 Hive 部署规划</li><li>确认 Hive 的安装包是否已经上传到 Ambari Server 节点的 <code>/var/www/html/ambari/extend</code> 路径下</li><li>确认 Hive 服务包是否已经上传到 Ambari Server 节点的 <code>/var/lib/ambari-server/resources/stacks/HDP/2.6/services</code> 路径下</li></ul><a id="more"></a><blockquote><p>如果版本包未上传，则需要上传到指定的目录，并且重启 ambari server</p></blockquote><hr><h2 id="2、安装部署-Hive"><a href="#2、安装部署-Hive" class="headerlink" title="2、安装部署 Hive"></a>2、安装部署 Hive</h2><p>点击 <code>Add Service</code> 选择 Hive 服务并点击 <code>NEXT</code><br><img src="http://cdn.winyter.cn/ambari-install-guide_image127.png" alt="image-127.png"></p><p>选择 Hive Metastore、HiveServer2 和 Hive Monitor 节点：</p><blockquote><p>Hive Monitor和Hive Metastore安装在同一台机器上</p></blockquote><p><img src="http://cdn.winyter.cn/ambari-install-guide_image128.png" alt="image-128.png"></p><p>选择 client 节点<br><img src="http://cdn.winyter.cn/ambari-install-guide_image129.png" alt="image-129.png"></p><p>点击 <code>NEXT</code> 按钮，进行配置界面，修改 Hive 配置文件</p><ul><li>修改 <strong>DATABASE</strong> 配置项<br><strong>Hive Database</strong> 选择 <code>Existing MySQL/MariaDB</code><br><strong>Database Name</strong> 可以自己起名，如果没有特殊要求的话，可以直接填写 <code>hive</code><br><strong>Database Username</strong> &amp; <strong>Database Password</strong> 填写之前安装的 MySQL 的业务用户名及密码，本文档此前使用的是 <code>rhino</code> 用户，密码为 <code>xxxxxxxx</code><br><strong>Database URL</strong> 即 MySQL 数据库的 jdbc 地址： <code>jdbc:mysql://10.0.0.32:3306/hive?createDatabaseIfNotExist=true</code><br>以上未提到的配置一般不需要修改，默认即可，需要注意一下字符集要为 <code>latin1</code></li></ul><p><img src="http://cdn.winyter.cn/ambari-install-guide_image130.png" alt="image-130.png"></p><ul><li><p>修改 ADVANCED 配置项下的 <strong>Advanced hive-env</strong><br><strong>Metrics Collector Host Ip</strong> 对应 metric collector 进程所在节点的 ip 地址；<br><strong>hive_download</strong> 地址 <code>http://172.168.1.1/ambari/extend/apache-hive-2.3.3-bin.tar.gz</code><br><strong>hive_monitor_download</strong>地址 http:// <code>172.168.1.1/ambari/extend/hive-monitor.tar.gz</code><br><strong>hiveserver_jmx</strong> 地址 <code>http://172.168.1.1:10002/jmx</code>，其中 ip 对应 hiveserver2 所在节点地址，端口取 hive.server2.webui.port 配置的端口。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image131.png" alt="image-131.png"></p></li><li><p>上传 <code>mysql-connector-java-5.1.40-bin.jar</code><br>将此前准备的基础版本包中的 MySQL JDBC 驱动包上传到 Ambari Server 节点的 <code>/var/lib/ambari-server/resources</code> 目录下</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]# cd &#x2F;home&#x2F;package&#x2F;base</span><br><span class="line">[root@node1 ~]# cp mysql-connector-java-5.1.40-bin.jar &#x2F;var&#x2F;lib&#x2F;ambari-server&#x2F;resources</span><br><span class="line">[root@node1 ~]# chmod 755 &#x2F;var&#x2F;lib&#x2F;ambari-server&#x2F;resources&#x2F;mysql-connector-java-5.1.40-bin.jar</span><br></pre></td></tr></table></figure></li></ul><hr><h2 id="3、确认安装"><a href="#3、确认安装" class="headerlink" title="3、确认安装"></a>3、确认安装</h2><p><img src="http://cdn.winyter.cn/ambari-install-guide_image132.png" alt="image-132.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image133.png" alt="image-133.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image134.png" alt="image-134.png"></p><hr><h2 id="4、完成安装"><a href="#4、完成安装" class="headerlink" title="4、完成安装"></a>4、完成安装</h2><p><img src="http://cdn.winyter.cn/ambari-install-guide_image135.png" alt="image-135.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image136.png" alt="image-136.png"></p><p>安装完成后，hive服务进程展示<br><img src="http://cdn.winyter.cn/ambari-install-guide_image137.png" alt="image-137.png"></p><hr><h2 id="5、修改-hdfs-配置文件"><a href="#5、修改-hdfs-配置文件" class="headerlink" title="5、修改 hdfs 配置文件"></a>5、修改 hdfs 配置文件</h2><p>Hive 服务默认用户是 hive，在 hdfs 的 <strong>Custom core-site</strong> 配置项下点击 <code>Add Property</code> 添加两个配置：<strong>hadoop.proxyuser.hive.groups</strong> 和 <strong>hadoop.proxyuser.hive.hosts</strong>，value都配置 <code>*</code> 。<br>然后重启 hdfs 和 yarn 服务。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image138.png" alt="image-138.png"></p><hr><h2 id="6、Hive-启停"><a href="#6、Hive-启停" class="headerlink" title="6、Hive 启停"></a>6、Hive 启停</h2><p>点击右上角ACTIONS里的Stop，即可执行停止服务操作</p><blockquote><p>Hive2.3.3 如果遇到进程无法启动的问题时。要手动按照此顺序启动进程：先启动 metadata 进程，然后启动 server 进程，最后启动 monitor 进程。Monitor 进程可能启动时会一直不成功，如果实在无法解决，可以忽略，monitor 进程不影响流程的运行，只起监控的作用。</p></blockquote><p><img src="http://cdn.winyter.cn/ambari-install-guide_image139.png" alt="image-139.png"></p><p>点击右上角ACTIONS里的Start，启动停止后的服务<br><img src="http://cdn.winyter.cn/ambari-install-guide_image140.png" alt="image-140.png"></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h2 id=&quot;1、准备工作&quot;&gt;&lt;a href=&quot;#1、准备工作&quot; class=&quot;headerlink&quot; title=&quot;1、准备工作&quot;&gt;&lt;/a&gt;1、准备工作&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;确认 Hive 版本，以及 Hive 部署规划&lt;/li&gt;
&lt;li&gt;确认 Hive 的安装包是否已经上传到 Ambari Server 节点的 &lt;code&gt;/var/www/html/ambari/extend&lt;/code&gt; 路径下&lt;/li&gt;
&lt;li&gt;确认 Hive 服务包是否已经上传到 Ambari Server 节点的 &lt;code&gt;/var/lib/ambari-server/resources/stacks/HDP/2.6/services&lt;/code&gt; 路径下&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="CS Soft" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/"/>
    
      <category term="Server" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/"/>
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/Ambari/"/>
    
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/tags/Ambari/"/>
    
      <category term="Bigdata" scheme="https://winyter.github.io/MyBlog/tags/Bigdata/"/>
    
  </entry>
  
  <entry>
    <title>基于 Ambari 的大数据集群安装指导——篇七：Ambari 安装 HBase</title>
    <link href="https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-7-install-hbase-md/"/>
    <id>https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-7-install-hbase-md/</id>
    <published>2020-05-31T09:43:42.000Z</published>
    <updated>2020-07-25T11:14:12.268Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="1、准备工作"><a href="#1、准备工作" class="headerlink" title="1、准备工作"></a>1、准备工作</h2><ul><li>确认 HBase 版本，以及 HBase 部署规划</li><li>确认 HBase 的安装包是否已经上传到 Ambari Server 节点的 <code>/var/www/html/ambari/extend</code> 路径下</li><li>确认 HBase 服务包是否已经上传到 Ambari Server 节点的 <code>/var/lib/ambari-server/resources/stacks/HDP/2.6/services</code> 路径下</li></ul><a id="more"></a><blockquote><p>如果版本包未上传，则需要上传到指定的目录，并且重启 ambari server</p></blockquote><hr><h2 id="2、安装部署-HBase"><a href="#2、安装部署-HBase" class="headerlink" title="2、安装部署 HBase"></a>2、安装部署 HBase</h2><p>点击 <code>Add Service</code> 选择 HBase 服务并点击 <code>NEXT</code><br><img src="http://cdn.winyter.cn/ambari-install-guide_image113.png" alt="image-113.png"></p><p>根据部署规划，添加 hbase Master 节点并点击 <code>NEXT</code>，可以添加多个，但如果没有特殊需求，一般添加一个即可<br><img src="http://cdn.winyter.cn/ambari-install-guide_image114.png" alt="image-114.png"></p><p>根据部署规划，选择 RegionServer 和 client 节点：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image115.png" alt="image-115.png"></p><p>--</p><h2 id="3、修改-Hbase-配置文件"><a href="#3、修改-Hbase-配置文件" class="headerlink" title="3、修改 Hbase 配置文件"></a>3、修改 Hbase 配置文件</h2><p>修改 <strong>Advanced hbase-env</strong> &gt;&gt; <strong>hbase_download</strong> 地址，<code>http://172.168.1.1/ambari/extend/hbase-1.4.9-bin.tar.gz</code>。（IP地址和包名称根据实际情况修改）<br><img src="http://cdn.winyter.cn/ambari-install-guide_image116.png" alt="iamge-116.png"></p><p>修改 <strong>Advanced hbase-site</strong> &gt;&gt; <strong>zookeeper znode parent</strong> 为 <code>/hbase</code>，否则安装完成无法使用 hbase<br><img src="http://cdn.winyter.cn/ambari-install-guide_image118.png" alt="image-118.png"></p><hr><h2 id="4、确认安装-Hbase"><a href="#4、确认安装-Hbase" class="headerlink" title="4、确认安装 Hbase"></a>4、确认安装 Hbase</h2><p>配置完成后一直点击下一步，执行安装部署：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image119.png" alt="image-119.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image120.png" alt="image-120.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image121.png" alt="image-121.png"></p><hr><h2 id="5、完成安装-Hbase"><a href="#5、完成安装-Hbase" class="headerlink" title="5、完成安装 Hbase"></a>5、完成安装 Hbase</h2><p><img src="http://cdn.winyter.cn/ambari-install-guide_image122.png" alt="image-122.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image123.png" alt="image-123.png"></p><p>安装完成后，hbase服务进程展示<br><img src="http://cdn.winyter.cn/ambari-install-guide_image124.png" alt="image-124.png"></p><hr><h2 id="6、启停"><a href="#6、启停" class="headerlink" title="6、启停"></a>6、启停</h2><p>点击右上角ACTIONS里的Stop，即可执行停止服务操作<br><img src="http://cdn.winyter.cn/ambari-install-guide_image125.png" alt="image-125.png"></p><p>点击右上角ACTIONS里的Start，启动停止后的服务<br><img src="http://cdn.winyter.cn/ambari-install-guide_image126.png" alt="image-126.png"></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h2 id=&quot;1、准备工作&quot;&gt;&lt;a href=&quot;#1、准备工作&quot; class=&quot;headerlink&quot; title=&quot;1、准备工作&quot;&gt;&lt;/a&gt;1、准备工作&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;确认 HBase 版本，以及 HBase 部署规划&lt;/li&gt;
&lt;li&gt;确认 HBase 的安装包是否已经上传到 Ambari Server 节点的 &lt;code&gt;/var/www/html/ambari/extend&lt;/code&gt; 路径下&lt;/li&gt;
&lt;li&gt;确认 HBase 服务包是否已经上传到 Ambari Server 节点的 &lt;code&gt;/var/lib/ambari-server/resources/stacks/HDP/2.6/services&lt;/code&gt; 路径下&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="CS Soft" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/"/>
    
      <category term="Server" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/"/>
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/Ambari/"/>
    
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/tags/Ambari/"/>
    
      <category term="Bigdata" scheme="https://winyter.github.io/MyBlog/tags/Bigdata/"/>
    
  </entry>
  
  <entry>
    <title>基于 Ambari 的大数据集群安装指导——篇六：Ambari 安装 ElasticSearch</title>
    <link href="https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-6-install-elasticsearch-md/"/>
    <id>https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-6-install-elasticsearch-md/</id>
    <published>2020-05-31T09:42:37.000Z</published>
    <updated>2020-07-25T11:14:17.516Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="1、准备工作"><a href="#1、准备工作" class="headerlink" title="1、准备工作"></a>1、准备工作</h2><ul><li>确认 ES 版本，以及 ES 部署规划</li><li>确认 ES 的安装包是否已经上传到 Ambari Server 节点的 <code>/var/www/html/ambari/extend</code> 路径下</li><li>确认 ES 服务包是否已经上传到 Ambari Server 节点的 <code>/var/lib/ambari-server/resources/stacks/HDP/2.6/services</code> 路径下</li></ul><a id="more"></a><blockquote><p>如果版本包未上传，则需要上传到指定的目录，并且重启 ambari server</p></blockquote><hr><h2 id="2、安装部署-ElasticSearch"><a href="#2、安装部署-ElasticSearch" class="headerlink" title="2、安装部署 ElasticSearch"></a>2、安装部署 ElasticSearch</h2><p>点击 <code>Add Service</code> 选择 Elasticsearch 服务并点击 <code>NEXT</code>：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image97.png" alt="image-97.png"></p><p>点击进入后找到 Elasticsearch Master，点击后面的 <code>+</code> 号按钮可以选择在哪几台服务器上部署 ES，例如选择 node1,node2 两台服务器部署 ES；此时 ES Monitor 只需选择 node1 或 node2 其中一台即可（ES Monitor不要单独安装）。如下图所示：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image99.png" alt="image-98.png"></p><hr><h2 id="3、修改ElasticSearch配置文件"><a href="#3、修改ElasticSearch配置文件" class="headerlink" title="3、修改ElasticSearch配置文件"></a>3、修改ElasticSearch配置文件</h2><p>选择好需要部署的服务器后点击next进入下一个界面，该界面比较重要，主要是配置一些常用的ES参数，以及ES多实例的配置（即在一台服务器启多个ES，提高入库性能）。</p><blockquote><p>安装版本时，默认会创建一个elastic用户和elastic组。这个用户就是 ES 的安装用户，绝大部分 ES 的维护，都需要在这个用户下操作</p></blockquote><ul><li><strong>Advanced elastic-config</strong> 配置组配置修改：</li></ul><p>&lt;1&gt; <strong>cluster_name</strong>：集群名称，可以修改成自己想要的集群名称，如果没有特别需求，可以直接设置成 elasticsearch，这里需要注意，ES 的集群名称与 Hadoop 的集群名称是不同的两个名称，不能搞混！<br>&lt;2&gt; <strong>discovery_zen_minimum_master_nodes</strong>：集群中主节点的数量，配置为1。<br>&lt;3&gt; <strong>discovery_zen_ping_unicast_hosts</strong>: 集群中 master 节点初始列表，如两台服务器安装了 ES Master，则配置为 172.168.1.1:9300,172.168.1.2:9300<br>&lt;4&gt; <strong>elastic_download</strong>： ES 版本下载地址，只需将默认值中的 ip 修改即可。<br>&lt;5&gt; <strong>gateway_recover_after_nodes</strong>：设置集群中 N 个节点启动时进行数据恢复，默认为 1。<br>&lt;6&gt; <strong>head_download</strong>： head-master 界面监控工具下载地址，只需修改 ip 即可。<br>&lt;7&gt; <strong>headmaster_ip</strong>：将 ip 修改为刚才 ES Monitor 对应的 ip。</p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image101.png" alt="image-101.png"></p><p>&lt;8&gt; <strong>http_port</strong>: HTTP 端口号，配置和实例个数有关。如果实例个数 为3，则配置9200,9201,9202</p><blockquote><p>注意：中间用英文逗号隔开。</p></blockquote><p>&lt;9&gt; <strong>init_heapspace</strong>：分配给堆内存的初始值，该值与 max_heapspace 值配置相同。如果该服务器有 30G 分配给 ES，每台服务器启 3 个实例，则该值配为 <code>-Xms26g</code>，该参数需要根据实际集群配置进行灵活调整</p><blockquote><p>注意：该值最大值最好配为 -Xms26g（服务器内存足的情况下），前面的 - 符号不能少。</p></blockquote><p>&lt;10&gt; <strong>max_heapspace</strong>：和 init_heapspace 值配置相同。<br>&lt;11&gt; <strong>nodejs_download</strong>: head-master 界面监控工具依赖 nodejs，该项配置 nodejs 下载地址，修改 ip 即可。<br>&lt;12&gt; <strong>path_data</strong>： ES 数据存储路径。现在默认所有实例中有 1 个实例只做 master，该实例不做 data，不存储数据；其余实例只做 data，不做 master。<br>比如该服务器启了 3 个 ES 实例，该服务器总共有 12 块盘，则第一个实例为 master，不存储数据；实际存储数据的为 2 个实例，则每个实例分配 6 块盘，则配置如下：<code>/home/elastic/esdata;/data01/esdata,/data02/esdata,/data03/esdata,/data04/esdata</code>, <code>/data05/esdata,/data06/esdata;/data07/esdata,/data08/esdata,/data09/esdata,/data10/esdata,/data11/esdata,/data12/esdata</code></p><blockquote><p>注意：其中/home/elastic/esdata是分配给实例1。data01、data02、data03、data04、data05、data06是分配给实例2，中间用英文逗号分开。实例1和实例2之间的英文用分号分开。同理实例2和实例3之间也是用英文分号分开。</p></blockquote><p>&lt;13&gt; <strong>path_logs</strong>： ES 启动及一些常用日志存放目录。配置和启动实例个数有关，例如需要启动 3 个实例，则配置为 <code>/home/elastic/elasticsearch/logs0; /home/elastic/elasticsearch/logs1; /home/elastic/elasticsearch/logs2</code>。其中实例1的日志写在 logs0 目录下，实例 2 的日志写在 logs1 目录下，实例3的日志写在 logs2 目录下。</p><blockquote><p>注意：不同目录之间用英文分号分开。</p></blockquote><p>&lt;14&gt; <strong>transport_tcp_port</strong>： TCP 端口号。配置和实例个数有关，如果实例个数为 3，则配置为 <code>9300,9301,9302</code></p><blockquote><p>注意：中间用英文逗号隔开</p></blockquote><p><img src="http://cdn.winyter.cn/ambari-install-guide_image102.png" alt="image-102.png"></p><ul><li>Advanced elastic-env配置项：<br>&lt;1&gt; <strong>elastic_base_dir</strong>： ES 版本解压后的安装目录<br>&lt;2&gt; <strong>elastic_log_dir</strong>： ES 安装日志目录（多实例时采用 path_logs 配置项）<br>&lt;3&gt; <strong>elastic_pid_dir</strong>： ES 启动时 pid 目录，ambari 检测 ES 是否安装成功时会检测该 pid。<br>&lt;4&gt; <strong>elastic_conf_dir</strong>: ES配置文件目录（暂时用不到）<br>&lt;5&gt; <strong>instance_num</strong>：多实例个数。一台服务器启动多少个 ES 就配置多少。如果不用多实例，只启动一个 ES 就配置为 1。默认为 3。</li></ul><p><img src="http://cdn.winyter.cn/ambari-install-guide_image103.png" alt="image-103.png"></p><ul><li>Advanced elastic-monitor配置项：<br>&lt;1&gt; <strong>es_host</strong>： 上报监控信息的ip地址，和ES Monitor选择的服务器ip相同即可。<br>&lt;2&gt; <strong>esmonitor_download</strong>： es监控包的下载地址，修改ip即可。<br>&lt;3&gt; <strong>metric_host</strong>： 填写Ambari Metrics的地址。</li></ul><p><img src="http://cdn.winyter.cn/ambari-install-guide_image104.png" alt="image-104.png"></p><blockquote><p>Metrics地址查看：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image105.png" alt="image-105.png"></p></blockquote><hr><h2 id="4、确认安装-ES"><a href="#4、确认安装-ES" class="headerlink" title="4、确认安装 ES"></a>4、确认安装 ES</h2><p>修改完成配置项后，点击下一步，进行安装。</p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image106.png" alt="image-106.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image108.png" alt="image-108.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image109.png" alt="image-109.png"></p><p>完成安装后，如果 ES Monitor 未启动，需要手动启动ES Monitor<br><img src="http://cdn.winyter.cn/ambari-install-guide_image110.png" alt="image-110.png"></p><p>ES正常启动后，可以看到左侧的Elasticsearch图标显示为绿色，也可在服务器后台输入命令： curl ip:9200/_cat/nodes,能看到启动的所有ES实例。</p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image111.png" alt="iamge-111.png"></p><blockquote><p>如果遇到提示 elastic 安装不成功，错误为 mkdir 权限被 denied，则自己手动在 home 下创建一个 elastic 的文件夹，用命令：<code>chown elastic:hadoop elastic/</code> 来手动更改一下权限，然后点重新安装即可。</p></blockquote><hr><h2 id="5、启停ElasticSearch"><a href="#5、启停ElasticSearch" class="headerlink" title="5、启停ElasticSearch"></a>5、启停ElasticSearch</h2><p>如果想停止ES服务，则可以先选择左侧的Elasticsearch，然后点击右上角ACTIONS，选择stop，点击CONFIRM STOP停止服务，如下图所示：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image112.png" alt="image-112.png"></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h2 id=&quot;1、准备工作&quot;&gt;&lt;a href=&quot;#1、准备工作&quot; class=&quot;headerlink&quot; title=&quot;1、准备工作&quot;&gt;&lt;/a&gt;1、准备工作&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;确认 ES 版本，以及 ES 部署规划&lt;/li&gt;
&lt;li&gt;确认 ES 的安装包是否已经上传到 Ambari Server 节点的 &lt;code&gt;/var/www/html/ambari/extend&lt;/code&gt; 路径下&lt;/li&gt;
&lt;li&gt;确认 ES 服务包是否已经上传到 Ambari Server 节点的 &lt;code&gt;/var/lib/ambari-server/resources/stacks/HDP/2.6/services&lt;/code&gt; 路径下&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="CS Soft" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/"/>
    
      <category term="Server" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/"/>
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/Ambari/"/>
    
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/tags/Ambari/"/>
    
      <category term="Bigdata" scheme="https://winyter.github.io/MyBlog/tags/Bigdata/"/>
    
  </entry>
  
  <entry>
    <title>基于 Ambari 的大数据集群安装指导——篇五：Ambari 安装 YARN</title>
    <link href="https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-5-install-yarn-md/"/>
    <id>https://winyter.github.io/MyBlog/2020/05/31/ambari-install-guides-5-install-yarn-md/</id>
    <published>2020-05-31T09:40:24.000Z</published>
    <updated>2020-07-25T11:13:25.595Z</updated>
    
    <content type="html"><![CDATA[<hr><h2 id="1、安装部署"><a href="#1、安装部署" class="headerlink" title="1、安装部署"></a>1、安装部署</h2><a id="more"></a><p>点击 <code>Add Service</code> 选择 YARN+MapReduce 服务并下拉到页面底部点击 <code>NEXT</code>：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image69.png" alt="image-69.png"></p><p>根据组件规划，选择 ResourceManager 节点，App Timeline Server 和 History Server 直接默认即可，不需要修改，点击 <code>NEXT</code>。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image70.png" alt="image-70.png"></p><p>选择 NodeManager 节点</p><blockquote><p>注意：NodeManager 和 client 部署方式与 DataNode 一致即可<br><img src="http://cdn.winyter.cn/ambari-install-guide_image71.png" alt="image-71.png"></p></blockquote><hr><h2 id="2、修改-YARN-配置文件"><a href="#2、修改-YARN-配置文件" class="headerlink" title="2、修改 YARN 配置文件"></a>2、修改 YARN 配置文件</h2><p><img src="http://cdn.winyter.cn/ambari-install-guide_image72.png" alt="iamge-72.png"></p><p>&lt;1&gt; <strong>Memory allocated for all YARN containers on a node</strong>：<br>该参数值为每个 nodemanager 节点可用内存。大小设置为单台 nodemanager 机器内存大小的80%。<br>&lt;2&gt; <strong>Minimum Container Size (Memory)</strong>：<br>该参数值为单个任务可申请最小内存。该值需要根据实际业务进行调整，如果不知道实际业务需求的话，建议往小了设置，根据集群总资源，设置一个比较小的参数（建议设置 2048）。该参数后期可以随时调整。<br>&lt;3&gt; <strong>Maximum Container Size (Memory)</strong>：<br>该参数值为单个任务可申请最大内存。该值可以设置为64G。<br>&lt;4&gt; <strong>Number of virtual cores</strong>：<br>该参数值设置为单台nodemanager机器cpu逻辑核数的一半。<br>&lt;5&gt; <strong>Maximum Container Size (VCores)</strong>：<br>该参数值必须小于或等于 Number of virtual cores 的值</p><blockquote><p>以上没有提到的配置，一般默认即可，如果实际有需求，也可以进行修改<br>查看CPU逻辑核数命令：<br>cat /proc/cpuinfo |grep processor |wc -l</p></blockquote><p><img src="http://cdn.winyter.cn/ambari-install-guide_image73.png" alt="image-73.png"></p><p>&lt;6&gt; <strong>YARN NodeManager Local directories</strong>：<br>该参数值填写 <code>/data01/hadoop/yarn/local,/data02/hadoop/yarn/local,/data03/hadoop/yarn/local,/data04/hadoop/yarn/local,/data05/hadoop/yarn/local,/data06/hadoop/yarn/local,/data07/hadoop/yarn/local,/data08/hadoop/yarn/local,/data09/hadoop/yarn/local,/data10/hadoop/yarn/local</code></p><p>&lt;7&gt; <strong>YARN NodeManager Log directories</strong>：<br>该参数值填写 <code>/data01/hadoop/yarn/log,/data02/hadoop/yarn/log,/data03/hadoop/yarn/log,/data04/hadoop/yarn/log,/data05/hadoop/yarn/log,/data06/hadoop/yarn/log,/data07/hadoop/yarn/log,/data08/hadoop/yarn/log,/data09/hadoop/yarn/log,/data10/hadoop/yarn/log</code></p><blockquote><p>以上这两个参数根据系统中实际的磁盘数量填写。另外，原则同 HDFS 磁盘选择，遵循木桶效应，即所有节点最多能使用的数据盘数量，取决于所有节点中，数据盘最少的那个节点的数据盘数量</p></blockquote><hr><h2 id="3、确认安装-YARN"><a href="#3、确认安装-YARN" class="headerlink" title="3、确认安装 YARN"></a>3、确认安装 YARN</h2><p><img src="http://cdn.winyter.cn/ambari-install-guide_image74.png" alt="image-74.png"></p><p>完成安装<br><img src="http://cdn.winyter.cn/ambari-install-guide_image75.png" alt="image-75.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image76.png" alt="image-76.png"></p><hr><h2 id="4、启停"><a href="#4、启停" class="headerlink" title="4、启停"></a>4、启停</h2><p><img src="http://cdn.winyter.cn/ambari-install-guide_image77.png" alt="image-77.png"></p><hr><h2 id="5、YARN-集群高可用"><a href="#5、YARN-集群高可用" class="headerlink" title="5、YARN 集群高可用"></a>5、YARN 集群高可用</h2><hr><h3 id="5-1-Get-Start"><a href="#5-1-Get-Start" class="headerlink" title="5.1 Get Start"></a>5.1 Get Start</h3><p>在 Ambari 主界面，点击 <code>YARN→ACTIONS→Enable ResourceManager HA</code> 进行高可用设置<br><img src="http://cdn.winyter.cn/ambari-install-guide_image78.png" alt="image-78.png"></p><p>按照界面提示，点击Next即可<br><img src="http://cdn.winyter.cn/ambari-install-guide_image79.png" alt="image-79.png"></p><hr><h3 id="5-2-指定standby-resourcemanager节点"><a href="#5-2-指定standby-resourcemanager节点" class="headerlink" title="5.2 指定standby-resourcemanager节点"></a>5.2 指定standby-resourcemanager节点</h3><p>根据部署方案，选择 standby-resourcemanager 管理节点。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image80.png" alt="image-80.png"></p><hr><h3 id="5-3-Review"><a href="#5-3-Review" class="headerlink" title="5.3 Review"></a>5.3 Review</h3><p>默认配置是readonly，不可修改，只可查看，直接点击Next即可<br><img src="http://cdn.winyter.cn/ambari-install-guide_image81.png" alt="iamge-81.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image82.png" alt="image-82.png"></p><hr><h3 id="5-4-Configure-Components"><a href="#5-4-Configure-Components" class="headerlink" title="5.4 Configure Components"></a>5.4 Configure Components</h3><p>自动完成安装及配置，如下图所示，点击complete即可。<br><img src="http://cdn.winyter.cn/ambari-install-guide_image83.png" alt="image-83.png"></p><p>可以使用 <code>jps</code> 查看对应两台机器上的 resourcemanager 和 nodemanager 进程，全部实现了高可用状态。【root用户操作】</p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image84.png" alt="image-84.png"></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image85.png" alt="image-85.png"></p><hr><h3 id="5-5-YARN-相关配置"><a href="#5-5-YARN-相关配置" class="headerlink" title="5.5 YARN 相关配置"></a>5.5 YARN 相关配置</h3><p><img src="http://cdn.winyter.cn/ambari-install-guide_image86.png" alt="image-86.png"></p><ul><li>Resource Manager配置</li></ul><p><strong>yarn.admin.acl</strong> = <code>yarn,rhino</code> </p><blockquote><p>resoucemanager 管理员权限用户配置，加上rhino用户，注意，这里安装文档以 rhino 用户为例，实际安装过程中，根据业务需求添加用户，可以直接配置为 *，即意味着所有用户均可以管理 ResourceManager（不建议这样配置）</p></blockquote><p><img src="http://cdn.winyter.cn/ambari-install-guide_image87.png" alt="image-87.png"></p><ul><li>Advanced yarn-site 配置：</li></ul><p><strong>yarn.client.failover-proxy-provider</strong> = <code>org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider</code><br><img src="http://cdn.winyter.cn/ambari-install-guide_image88.png" alt="image-88.png"></p><ul><li>NodeManager 配置</li></ul><p>该组配置安装 Yarn 时就已经修改过，只需检查一下即可<br><img src="http://cdn.winyter.cn/ambari-install-guide_image90.png" alt="image-90.png"></p><ul><li>Setting 配置</li></ul><p><img src="http://cdn.winyter.cn/ambari-install-guide_image89.png" alt="image-89.png"></p><ul><li>Scheduler 配置</li></ul><p><img src="http://cdn.winyter.cn/ambari-install-guide_image91.png" alt="image-91.png"><br>修改为 <code>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</code></p><blockquote><p>注意：修改yarn.resourcemanager.scheduler.class后，启动yarn之前要先添加fair-scheduler.xml文件，不然启动yarn会报错找不到fair-scheduler.xml，需要配置<br>fair-scheduler.xml文件只需要拷贝到两台ResourceManager机器上</p></blockquote><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]# cd &#x2F;usr&#x2F;hdp&#x2F;2.6.3.0-235&#x2F;hadoop-yarn&#x2F;etc&#x2F;hadoop&#x2F;</span><br><span class="line">[root@node1 hadoop]# chown yarn:hadoop fair-scheduler.xml</span><br><span class="line">[root@node1 hadoop]# scp fair-scheduler.xml root@node2:&#x2F;usr&#x2F;hdp&#x2F;2.6.3.0-235&#x2F;hadoop-yarn&#x2F;etc&#x2F;hadoop&#x2F;</span><br></pre></td></tr></table></figure><p>如果没有找到该文件，可以直接在目录下新建这个文件</p><p>fair-scheduler.xml 需要进行配置，详细配置方法<a href="https://winyter.github.io/MyBlog/2020/05/23/yarn-fair-scheduler-guide/" target="_blank" rel="noopener">点击这里</a></p><ul><li>Custom yarn-site中增加配置项：</li></ul><p><img src="http://cdn.winyter.cn/ambari-install-guide_image92.png" alt="image-92.png"></p><p><strong>yarn.scheduler.fair.allocation.file</strong> = <code>/usr/hdp/2.6.3.0-235/hadoop-yarn/etc/hadoop/fair-scheduler.xml</code><br><strong>hdp.version</strong> = <code>2.6.3.0-235</code><br><strong>yarn.nodemanager.localizer.cache.target-size-mb</strong> = <code>1024</code><br><strong>yarn.nodemanager.localizer.cache.cleanup.interval-ms</strong> = <code>60000</code></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image93.png" alt="image-93.png"></p><blockquote><p>注意：安装ambari 2.7版本的时候，出现因为路径的有空格导致找不到文件，需要注意路径格式。</p></blockquote><hr><h3 id="5-6-YARN-日志老化配置"><a href="#5-6-YARN-日志老化配置" class="headerlink" title="5.6 YARN 日志老化配置"></a>5.6 YARN 日志老化配置</h3><p>找到yarn-log4j的配置项：<br><img src="http://cdn.winyter.cn/ambari-install-guide_image94.png" alt="image-94.png"></p><p>按照以下内容进行修改</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Audit logging for ResourceManager</span><br><span class="line">rm.audit.logger&#x3D;$&#123;hadoop.root.logger&#125;</span><br><span class="line">log4j.logger.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger&#x3D;$&#123;rm.audit.logger&#125;</span><br><span class="line">log4j.additivity.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger&#x3D;false</span><br><span class="line">log4j.appender.RMAUDIT&#x3D;org.apache.log4j.DailyRollingFileAppender</span><br><span class="line">log4j.appender.RMAUDIT.File&#x3D;$&#123;yarn.log.dir&#125;&#x2F;rm-audit.log</span><br><span class="line">log4j.appender.RMAUDIT.layout&#x3D;org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.RMAUDIT.layout.ConversionPattern&#x3D;%d&#123;ISO8601&#125; %p %c&#123;2&#125;: %m%n</span><br><span class="line">log4j.appender.RMAUDIT.DatePattern&#x3D;.yyyy-MM-dd</span><br><span class="line"></span><br><span class="line">改为:</span><br><span class="line"></span><br><span class="line"># Audit logging for ResourceManager</span><br><span class="line">rm.audit.logger&#x3D;$&#123;hadoop.root.logger&#125;</span><br><span class="line">log4j.logger.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger&#x3D;$&#123;rm.audit.logger&#125;</span><br><span class="line">log4j.additivity.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger&#x3D;false</span><br><span class="line">log4j.appender.RMAUDIT&#x3D;org.apache.log4j.RollingFileAppender</span><br><span class="line">log4j.appender.RMAUDIT.File&#x3D;$&#123;yarn.log.dir&#125;&#x2F;rm-audit.log</span><br><span class="line">log4j.appender.RMAUDIT.layout&#x3D;org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.RMAUDIT.layout.ConversionPattern&#x3D;%d&#123;ISO8601&#125; %p %c&#123;2&#125;: %m%n</span><br><span class="line">log4j.appender.RMAUDIT.MaxFileSize&#x3D;128MB</span><br><span class="line">log4j.appender.RMAUDIT.MaxBackupIndex&#x3D;5</span><br><span class="line"></span><br><span class="line">------------------------------- 我是分割线 -----------------------------------</span><br><span class="line"></span><br><span class="line"># Audit logging for NodeManager</span><br><span class="line">nm.audit.logger&#x3D;$&#123;hadoop.root.logger&#125;</span><br><span class="line">log4j.logger.org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger&#x3D;$&#123;nm.audit.logger&#125;</span><br><span class="line">log4j.additivity.org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger&#x3D;false</span><br><span class="line">log4j.appender.NMAUDIT&#x3D;org.apache.log4j.DailyRollingFileAppender</span><br><span class="line">log4j.appender.NMAUDIT.File&#x3D;$&#123;yarn.log.dir&#125;&#x2F;nm-audit.log</span><br><span class="line">log4j.appender.NMAUDIT.layout&#x3D;org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.NMAUDIT.layout.ConversionPattern&#x3D;%d&#123;ISO8601&#125; %p %c&#123;2&#125;: %m%n</span><br><span class="line">log4j.appender.NMAUDIT.DatePattern&#x3D;.yyyy-MM-dd</span><br><span class="line"></span><br><span class="line">改为:</span><br><span class="line"></span><br><span class="line"># Audit logging for NodeManager</span><br><span class="line">nm.audit.logger&#x3D;$&#123;hadoop.root.logger&#125;</span><br><span class="line">log4j.logger.org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger&#x3D;$&#123;nm.audit.logger&#125;</span><br><span class="line">log4j.additivity.org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger&#x3D;false</span><br><span class="line">log4j.appender.NMAUDIT&#x3D;org.apache.log4j.RollingFileAppender</span><br><span class="line">log4j.appender.NMAUDIT.File&#x3D;$&#123;yarn.log.dir&#125;&#x2F;nm-audit.log</span><br><span class="line">log4j.appender.NMAUDIT.layout&#x3D;org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.NMAUDIT.layout.ConversionPattern&#x3D;%d&#123;ISO8601&#125; %p %c&#123;2&#125;: %m%n</span><br><span class="line">log4j.appender.NMAUDIT.MaxFileSize&#x3D;128MB</span><br><span class="line">log4j.appender.NMAUDIT.MaxBackupIndex&#x3D;5</span><br></pre></td></tr></table></figure><p><img src="http://cdn.winyter.cn/ambari-install-guide_image95.png" alt="image-95.png"></p><hr><h3 id="5-7-MapReduced配置"><a href="#5-7-MapReduced配置" class="headerlink" title="5.7 MapReduced配置"></a>5.7 MapReduced配置</h3><p>在 MapReduce 的 Custom mapred-site 里增加配置项：<br><strong>hdp.version</strong> = <code>2.6.3.0-235</code></p><p><img src="http://cdn.winyter.cn/ambari-install-guide_image96.png" alt="image-96.png"></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;h2 id=&quot;1、安装部署&quot;&gt;&lt;a href=&quot;#1、安装部署&quot; class=&quot;headerlink&quot; title=&quot;1、安装部署&quot;&gt;&lt;/a&gt;1、安装部署&lt;/h2&gt;
    
    </summary>
    
    
      <category term="CS Soft" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/"/>
    
      <category term="Server" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/"/>
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/categories/CS-Soft/Server/Ambari/"/>
    
    
      <category term="Ambari" scheme="https://winyter.github.io/MyBlog/tags/Ambari/"/>
    
      <category term="Bigdata" scheme="https://winyter.github.io/MyBlog/tags/Bigdata/"/>
    
  </entry>
  
</feed>
